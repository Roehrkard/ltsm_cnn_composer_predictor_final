{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 336058,
     "status": "ok",
     "timestamp": 1721607493702,
     "user": {
      "displayName": "Aryaz Zomorodi",
      "userId": "03185736980681493432"
     },
     "user_tz": 420
    },
    "id": "GwwHW4eJnxwq",
    "outputId": "01dbd07d-68e5-424e-bb29-8d047ddfb3f6"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 126\u001b[0m\n\u001b[1;32m    123\u001b[0m y \u001b[38;5;241m=\u001b[39m to_categorical(labels, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m# Split data\u001b[39;00m\n\u001b[0;32m--> 126\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# Build and train models\u001b[39;00m\n\u001b[1;32m    129\u001b[0m lstm_model \u001b[38;5;241m=\u001b[39m build_lstm_model((X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m~/myenv/lib/python3.9/site-packages/sklearn/model_selection/_split.py:2562\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2559\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[1;32m   2561\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m-> 2562\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2563\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\n\u001b[1;32m   2564\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2566\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m   2567\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/myenv/lib/python3.9/site-packages/sklearn/model_selection/_split.py:2236\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2233\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[1;32m   2235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2236\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2237\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2238\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2239\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[1;32m   2240\u001b[0m     )\n\u001b[1;32m   2242\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Install pretty_midi\n",
    "!pip install pretty_midi\n",
    "\n",
    "import pretty_midi\n",
    "\n",
    "# Mount Google Drive\n",
    "# from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Data Pre-processing\n",
    "def preprocess_data(midi_files):\n",
    "    midi_data = []\n",
    "    for file in midi_files:\n",
    "        try:\n",
    "            midi = pretty_midi.PrettyMIDI(file)\n",
    "            midi_data.append(midi)\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping file {file} due to error: {e}\")\n",
    "    # Apply data augmentation techniques if necessary\n",
    "    return midi_data\n",
    "\n",
    "# Feature Extraction\n",
    "def extract_features(midi_data, composer_label):\n",
    "    features = []\n",
    "    labels = []\n",
    "    for midi in midi_data:\n",
    "        # Extract features such as notes, chords, tempo\n",
    "        notes = midi.instruments[0].notes\n",
    "        pitch_sequence = [note.pitch for note in notes]  # Example feature: pitch of notes\n",
    "        features.append(pitch_sequence)\n",
    "        labels.append(composer_label)\n",
    "    return features, labels\n",
    "\n",
    "# Model Building\n",
    "def build_lstm_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, input_shape=input_shape, return_sequences=True))\n",
    "    model.add(LSTM(128))\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def build_cnn_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(64, kernel_size=3, activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Model Training\n",
    "def train_model(model, X_train, y_train, X_val, y_val):\n",
    "    history = model.fit(X_train, y_train, epochs=50, validation_data=(X_val, y_val))\n",
    "    return history\n",
    "\n",
    "# Model Evaluation\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_true = np.argmax(y_test, axis=1)\n",
    "    accuracy = accuracy_score(y_true, y_pred_classes)\n",
    "    precision = precision_score(y_true, y_pred_classes, average='macro')\n",
    "    recall = recall_score(y_true, y_pred_classes, average='macro')\n",
    "    return accuracy, precision, recall\n",
    "\n",
    "# Function to get MIDI file paths from a directory\n",
    "def get_midi_files_from_directory(directory_path):\n",
    "    midi_files = []\n",
    "    for root, _, files in os.walk(directory_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.mid') or file.endswith('.midi'):\n",
    "                midi_files.append(os.path.join(root, file))\n",
    "    return midi_files\n",
    "\n",
    "# Main\n",
    "if __name__ == \"__main__\":\n",
    "    # Base directory in Google Drive\n",
    "    base_directory = '/content/drive/My Drive/Colab Notebooks/midiclassics'\n",
    "\n",
    "    # Specify the subdirectories containing MIDI files\n",
    "    composers = {\n",
    "        'Bach': 0,\n",
    "        'Beethoven': 1,\n",
    "        'Chopin': 2,\n",
    "        'Mozart': 3\n",
    "    }\n",
    "\n",
    "    midi_files = []\n",
    "    labels = []\n",
    "\n",
    "    # Get MIDI files from directories and assign labels\n",
    "    for composer, label in composers.items():\n",
    "        composer_directory = os.path.join(base_directory, composer)\n",
    "        composer_files = get_midi_files_from_directory(composer_directory)\n",
    "        composer_features, composer_labels = extract_features(preprocess_data(composer_files), label)\n",
    "        midi_files.extend(composer_features)\n",
    "        labels.extend(composer_labels)\n",
    "\n",
    "    # Pad sequences to ensure they have the same length\n",
    "    max_sequence_length = 1000  # You can adjust this value based on your data\n",
    "    midi_files_padded = pad_sequences(midi_files, maxlen=max_sequence_length, padding='post', truncating='post')\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    midi_files = np.array(midi_files_padded)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Reshape data to fit model input requirements\n",
    "    X = midi_files.reshape(midi_files.shape[0], midi_files.shape[1], 1)\n",
    "    y = to_categorical(labels, num_classes=4)\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Build and train models\n",
    "    lstm_model = build_lstm_model((X_train.shape[1], 1))\n",
    "    cnn_model = build_cnn_model((X_train.shape[1], 1))\n",
    "    lstm_history = train_model(lstm_model, X_train, y_train, X_test, y_test)\n",
    "    cnn_history = train_model(cnn_model, X_train, y_train, X_test, y_test)\n",
    "\n",
    "    # Evaluate models\n",
    "    lstm_accuracy, lstm_precision, lstm_recall = evaluate_model(lstm_model, X_test, y_test)\n",
    "    cnn_accuracy, cnn_precision, cnn_recall = evaluate_model(cnn_model, X_test, y_test)\n",
    "\n",
    "    # Print evaluation results\n",
    "    print(f\"LSTM Model - Accuracy: {lstm_accuracy}, Precision: {lstm_precision}, Recall: {lstm_recall}\")\n",
    "    print(f\"CNN Model - Accuracy: {cnn_accuracy}, Precision: {cnn_precision}, Recall: {cnn_recall}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 630681,
     "status": "ok",
     "timestamp": 1721619426518,
     "user": {
      "displayName": "Aryaz Zomorodi",
      "userId": "03185736980681493432"
     },
     "user_tz": 420
    },
    "id": "wSqe4N3R9o5p",
    "outputId": "671a80b6-bdf3-43b8-94d2-21bfb120836a"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_categorical\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequence\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pad_sequences\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Mount Google Drive\u001b[39;00m\n\u001b[1;32m     15\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pretty_midi\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from google.colab import drive\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Custom wrapper\n",
    "class KerasClassifierCustom:\n",
    "    def __init__(self, build_fn=None, **sk_params):\n",
    "        self.build_fn = build_fn\n",
    "        self.sk_params = sk_params\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, X, y, **fit_params):\n",
    "        self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n",
    "        return self.model.fit(X, y, **fit_params)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "        y_true = np.argmax(y, axis=1)\n",
    "        return accuracy_score(y_true, y_pred_classes)\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        params = self.sk_params.copy()\n",
    "        params['build_fn'] = self.build_fn\n",
    "        return params\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        for key, value in params.items():\n",
    "            if key == \"build_fn\":\n",
    "                self.build_fn = value\n",
    "            else:\n",
    "                self.sk_params[key] = value\n",
    "        return self\n",
    "\n",
    "    def filter_sk_params(self, fn):\n",
    "        res = {}\n",
    "        fn_params = fn.__code__.co_varnames[:fn.__code__.co_argcount]\n",
    "        for name, value in self.sk_params.items():\n",
    "            if name in fn_params:\n",
    "                res[name] = value\n",
    "        return res\n",
    "\n",
    "# Model Building\n",
    "def create_lstm_model(optimizer='adam', units=128, dropout_rate=0.2):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units, input_shape=(max_sequence_length, 1), return_sequences=True))\n",
    "    model.add(LSTM(units))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def create_cnn_model(optimizer='adam', filters=64, kernel_size=3, dropout_rate=0.2):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters, kernel_size=kernel_size, activation='relu', input_shape=(max_sequence_length, 1)))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Function to get MIDI file paths from a directory\n",
    "def get_midi_files_from_directory(directory_path):\n",
    "    midi_files = []\n",
    "    for root, _, files in os.walk(directory_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.mid') or file.endswith('.midi'):\n",
    "                midi_files.append(os.path.join(root, file))\n",
    "    return midi_files\n",
    "\n",
    "# Data Pre-processing\n",
    "def preprocess_data(midi_files):\n",
    "    midi_data = []\n",
    "    for file in midi_files:\n",
    "        try:\n",
    "            midi = pretty_midi.PrettyMIDI(file)\n",
    "            midi_data.append(midi)\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping file {file} due to error: {e}\")\n",
    "    return midi_data\n",
    "\n",
    "# Data Augmentation\n",
    "def augment_data(sequence):\n",
    "    shift = np.random.randint(-5, 6)\n",
    "    return np.clip(np.array(sequence) + shift, 0, 127)\n",
    "\n",
    "# Feature Extraction\n",
    "def extract_features(midi_data, composer_label):\n",
    "    features = []\n",
    "    labels = []\n",
    "    for midi in midi_data:\n",
    "        if len(midi.instruments) > 0:\n",
    "            notes = midi.instruments[0].notes\n",
    "            pitch_sequence = [note.pitch for note in notes]\n",
    "            features.append(pitch_sequence)\n",
    "            labels.append(composer_label)\n",
    "    return features, labels\n",
    "\n",
    "# Model evaluation function\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_true = np.argmax(y_test, axis=1)\n",
    "    accuracy = accuracy_score(y_true, y_pred_classes)\n",
    "    precision = precision_score(y_true, y_pred_classes, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred_classes, average='weighted', zero_division=0)\n",
    "    return accuracy, precision, recall\n",
    "\n",
    "# Main\n",
    "if __name__ == \"__main__\":\n",
    "    # Base directory in Google Drive\n",
    "    base_directory = '/content/drive/My Drive/Colab Notebooks/midiclassics'\n",
    "\n",
    "    # Specify the subdirectories containing MIDI files\n",
    "    composers = {\n",
    "        'Bach': 0,\n",
    "        'Beethoven': 1,\n",
    "        'Chopin': 2,\n",
    "        'Mozart': 3\n",
    "    }\n",
    "\n",
    "    midi_files = []\n",
    "    labels = []\n",
    "\n",
    "    # Get MIDI files from directories and assign labels\n",
    "    for composer, label in composers.items():\n",
    "        composer_directory = os.path.join(base_directory, composer)\n",
    "        composer_files = get_midi_files_from_directory(composer_directory)\n",
    "        if not composer_files:\n",
    "            print(f\"No MIDI files found for {composer}\")\n",
    "        composer_features, composer_labels = extract_features(preprocess_data(composer_files), label)\n",
    "        if not composer_features:\n",
    "            print(f\"No features extracted for {composer}\")\n",
    "        augmented_features = [augment_data(seq) for seq in composer_features]\n",
    "        midi_files.extend(composer_features)\n",
    "        midi_files.extend(augmented_features)\n",
    "        labels.extend(composer_labels)\n",
    "        labels.extend(composer_labels)  # Augmented data has the same labels\n",
    "\n",
    "    # Pad sequences to ensure they have the same length\n",
    "    max_sequence_length = 1000  # You can adjust this value based on your data\n",
    "    midi_files_padded = pad_sequences(midi_files, maxlen=max_sequence_length, padding='post', truncating='post')\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    midi_files = np.array(midi_files_padded)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Check if dataset is empty\n",
    "    if midi_files.shape[0] == 0:\n",
    "        raise ValueError(\"No data available after preprocessing. Check your MIDI files and preprocessing steps.\")\n",
    "\n",
    "    # Reshape data to fit model input requirements\n",
    "    X = midi_files.reshape(midi_files.shape[0], midi_files.shape[1], 1)\n",
    "    y = to_categorical(labels, num_classes=4)\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Example usage with LSTM model\n",
    "    lstm_model_custom = KerasClassifierCustom(build_fn=create_lstm_model, epochs=10, batch_size=32, verbose=0)\n",
    "    cnn_model_custom = KerasClassifierCustom(build_fn=create_cnn_model, epochs=10, batch_size=32, verbose=0)\n",
    "\n",
    "    # Hyperparameter tuning for LSTM model\n",
    "    lstm_param_grid = {\n",
    "        'epochs': [50],\n",
    "        'batch_size': [32],\n",
    "        'optimizer': ['rmsprop'],\n",
    "        'units': [64],\n",
    "        'dropout_rate': [0.2]\n",
    "    }\n",
    "    lstm_grid = GridSearchCV(estimator=lstm_model_custom, param_grid=lstm_param_grid, n_jobs=-1, cv=3, error_score='raise')\n",
    "    lstm_grid_result = lstm_grid.fit(X_train, y_train)\n",
    "\n",
    "    # Hyperparameter tuning for CNN model\n",
    "    cnn_param_grid = {\n",
    "        'epochs': [100],\n",
    "        'batch_size': [32],\n",
    "        'optimizer': ['adam'],\n",
    "        'filters': [32],\n",
    "        'kernel_size': [3],\n",
    "        'dropout_rate': [0.5]\n",
    "    }\n",
    "    cnn_grid = GridSearchCV(estimator=cnn_model_custom, param_grid=cnn_param_grid, n_jobs=-1, cv=3, error_score='raise')\n",
    "    cnn_grid_result = cnn_grid.fit(X_train, y_train)\n",
    "\n",
    "    # Print the best hyperparameters for both models\n",
    "    print(f\"Best LSTM Model: {lstm_grid_result.best_score_} using {lstm_grid_result.best_params_}\")\n",
    "    print(f\"Best CNN Model: {cnn_grid_result.best_score_} using {cnn_grid_result.best_params_}\")\n",
    "\n",
    "    # Evaluate the best LSTM model\n",
    "    best_lstm_model = lstm_grid_result.best_estimator_.model\n",
    "    lstm_accuracy, lstm_precision, lstm_recall = evaluate_model(best_lstm_model, X_test, y_test)\n",
    "\n",
    "    # Evaluate the best CNN model\n",
    "    best_cnn_model = cnn_grid_result.best_estimator_.model\n",
    "    cnn_accuracy, cnn_precision, cnn_recall = evaluate_model(best_cnn_model, X_test, y_test)\n",
    "\n",
    "    # Print evaluation results\n",
    "    print(f\"LSTM Model - Accuracy: {lstm_accuracy}, Precision: {lstm_precision}, Recall: {lstm_recall}\")\n",
    "    print(f\"CNN Model - Accuracy: {cnn_accuracy}, Precision: {cnn_precision}, Recall: {cnn_recall}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 810446,
     "status": "ok",
     "timestamp": 1721620596570,
     "user": {
      "displayName": "Aryaz Zomorodi",
      "userId": "03185736980681493432"
     },
     "user_tz": 420
    },
    "id": "dakz-gvrhr_w",
    "outputId": "70ca1fa8-93b8-4908-fd42-ff94b574667d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping file /content/drive/My Drive/Colab Notebooks/midiclassics/Beethoven/Anhang 14-3.mid due to error: Could not decode key with 3 flats and mode 255\n",
      "Skipping file /content/drive/My Drive/Colab Notebooks/midiclassics/Mozart/Piano Sonatas/Nueva carpeta/K281 Piano Sonata n03 3mov.mid due to error: Could not decode key with 2 flats and mode 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 134s 1s/step - loss: 1.0418 - accuracy: 0.6032\n",
      "115/115 [==============================] - 5s 37ms/step - loss: 8.9786 - accuracy: 0.5438\n",
      "Best LSTM Model: 0.6029414847893998 using {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 50, 'optimizer': 'rmsprop', 'units': 64}\n",
      "Best CNN Model: 0.6152119830900645 using {'batch_size': 32, 'dropout_rate': 0.5, 'epochs': 100, 'filters': 64, 'kernel_size': 5, 'optimizer': 'adam'}\n",
      "29/29 [==============================] - 11s 363ms/step\n",
      "29/29 [==============================] - 1s 15ms/step\n",
      "LSTM Model - Accuracy: 0.6019629225736096, Precision: 0.5331888488829879, Recall: 0.6019629225736096\n",
      "CNN Model - Accuracy: 0.6150490730643402, Precision: 0.5312179105085324, Recall: 0.6150490730643402\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pretty_midi\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from google.colab import drive\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Custom wrapper\n",
    "class KerasClassifierCustom:\n",
    "    def __init__(self, build_fn=None, **sk_params):\n",
    "        self.build_fn = build_fn\n",
    "        self.sk_params = sk_params\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, X, y, **fit_params):\n",
    "        self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n",
    "        return self.model.fit(X, y, **fit_params)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "        y_true = np.argmax(y, axis=1)\n",
    "        return accuracy_score(y_true, y_pred_classes)\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        params = self.sk_params.copy()\n",
    "        params['build_fn'] = self.build_fn\n",
    "        return params\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        for key, value in params.items():\n",
    "            if key == \"build_fn\":\n",
    "                self.build_fn = value\n",
    "            else:\n",
    "                self.sk_params[key] = value\n",
    "        return self\n",
    "\n",
    "    def filter_sk_params(self, fn):\n",
    "        res = {}\n",
    "        fn_params = fn.__code__.co_varnames[:fn.__code__.co_argcount]\n",
    "        for name, value in self.sk_params.items():\n",
    "            if name in fn_params:\n",
    "                res[name] = value\n",
    "        return res\n",
    "\n",
    "# Model Building\n",
    "def create_lstm_model(optimizer='adam', units=128, dropout_rate=0.2):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units, input_shape=(max_sequence_length, 1), return_sequences=True))\n",
    "    model.add(LSTM(units))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def create_cnn_model(optimizer='adam', filters=64, kernel_size=3, dropout_rate=0.2):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters, kernel_size=kernel_size, activation='relu', input_shape=(max_sequence_length, 1)))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Function to get MIDI file paths from a directory\n",
    "def get_midi_files_from_directory(directory_path):\n",
    "    midi_files = []\n",
    "    for root, _, files in os.walk(directory_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.mid') or file.endswith('.midi'):\n",
    "                midi_files.append(os.path.join(root, file))\n",
    "    return midi_files\n",
    "\n",
    "# Data Pre-processing\n",
    "def preprocess_data(midi_files):\n",
    "    midi_data = []\n",
    "    for file in midi_files:\n",
    "        try:\n",
    "            midi = pretty_midi.PrettyMIDI(file)\n",
    "            midi_data.append(midi)\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping file {file} due to error: {e}\")\n",
    "    return midi_data\n",
    "\n",
    "# Improved Data Augmentation\n",
    "def augment_data(sequence):\n",
    "    shift = np.random.randint(-5, 6)\n",
    "    stretched_sequence = np.interp(np.linspace(0, len(sequence), len(sequence) * 2), np.arange(len(sequence)), sequence)\n",
    "    return np.clip(np.array(sequence) + shift, 0, 127), np.clip(stretched_sequence, 0, 127)\n",
    "\n",
    "# Feature Extraction\n",
    "def extract_features(midi_data, composer_label):\n",
    "    features = []\n",
    "    labels = []\n",
    "    for midi in midi_data:\n",
    "        if len(midi.instruments) > 0:\n",
    "            notes = midi.instruments[0].notes\n",
    "            pitch_sequence = [note.pitch for note in notes]\n",
    "            features.append(pitch_sequence)\n",
    "            labels.append(composer_label)\n",
    "    return features, labels\n",
    "\n",
    "# Model evaluation function\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_true = np.argmax(y_test, axis=1)\n",
    "    accuracy = accuracy_score(y_true, y_pred_classes)\n",
    "    precision = precision_score(y_true, y_pred_classes, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred_classes, average='weighted', zero_division=0)\n",
    "    return accuracy, precision, recall\n",
    "\n",
    "# Main\n",
    "if __name__ == \"__main__\":\n",
    "    # Base directory in Google Drive\n",
    "    base_directory = '/content/drive/My Drive/Colab Notebooks/midiclassics'\n",
    "\n",
    "    # Specify the subdirectories containing MIDI files\n",
    "    composers = {\n",
    "        'Bach': 0,\n",
    "        'Beethoven': 1,\n",
    "        'Chopin': 2,\n",
    "        'Mozart': 3\n",
    "    }\n",
    "\n",
    "    midi_files = []\n",
    "    labels = []\n",
    "\n",
    "    # Get MIDI files from directories and assign labels\n",
    "    for composer, label in composers.items():\n",
    "        composer_directory = os.path.join(base_directory, composer)\n",
    "        composer_files = get_midi_files_from_directory(composer_directory)\n",
    "        if not composer_files:\n",
    "            print(f\"No MIDI files found for {composer}\")\n",
    "        composer_features, composer_labels = extract_features(preprocess_data(composer_files), label)\n",
    "        if not composer_features:\n",
    "            print(f\"No features extracted for {composer}\")\n",
    "        for seq in composer_features:\n",
    "            augmented_seq, stretched_seq = augment_data(seq)\n",
    "            midi_files.append(seq)\n",
    "            midi_files.append(augmented_seq)\n",
    "            midi_files.append(stretched_seq)\n",
    "            labels.extend([label] * 3)\n",
    "\n",
    "    # Pad sequences to ensure they have the same length\n",
    "    max_sequence_length = 1000  # You can adjust this value based on your data\n",
    "    midi_files_padded = pad_sequences(midi_files, maxlen=max_sequence_length, padding='post', truncating='post')\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    midi_files = np.array(midi_files_padded)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Check if dataset is empty\n",
    "    if midi_files.shape[0] == 0:\n",
    "        raise ValueError(\"No data available after preprocessing. Check your MIDI files and preprocessing steps.\")\n",
    "\n",
    "    # Reshape data to fit model input requirements\n",
    "    X = midi_files.reshape(midi_files.shape[0], midi_files.shape[1], 1)\n",
    "    y = to_categorical(labels, num_classes=4)\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Example usage with LSTM model\n",
    "    lstm_model_custom = KerasClassifierCustom(build_fn=create_lstm_model, epochs=10, batch_size=32, verbose=0)\n",
    "    cnn_model_custom = KerasClassifierCustom(build_fn=create_cnn_model, epochs=10, batch_size=32, verbose=0)\n",
    "\n",
    "    # Hyperparameter tuning for LSTM model\n",
    "    lstm_param_grid = {\n",
    "        'epochs': [50],\n",
    "        'batch_size': [32],\n",
    "        'optimizer': ['rmsprop'],\n",
    "        'units': [64],\n",
    "        'dropout_rate': [0.2]\n",
    "    }\n",
    "    lstm_grid = GridSearchCV(estimator=lstm_model_custom, param_grid=lstm_param_grid, n_jobs=-1, cv=3, error_score='raise')\n",
    "    lstm_grid_result = lstm_grid.fit(X_train, y_train)\n",
    "\n",
    "    # Hyperparameter tuning for CNN model\n",
    "    cnn_param_grid = {\n",
    "        'epochs': [100],\n",
    "        'batch_size': [32],\n",
    "        'optimizer': ['adam'],\n",
    "        'filters': [32, 64],\n",
    "        'kernel_size': [3, 5],\n",
    "        'dropout_rate': [0.5]\n",
    "    }\n",
    "    cnn_grid = GridSearchCV(estimator=cnn_model_custom, param_grid=cnn_param_grid, n_jobs=-1, cv=3, error_score='raise')\n",
    "    cnn_grid_result = cnn_grid.fit(X_train, y_train)\n",
    "\n",
    "    # Print the best hyperparameters for both models\n",
    "    print(f\"Best LSTM Model: {lstm_grid_result.best_score_} using {lstm_grid_result.best_params_}\")\n",
    "    print(f\"Best CNN Model: {cnn_grid_result.best_score_} using {cnn_grid_result.best_params_}\")\n",
    "\n",
    "    # Evaluate the best LSTM model\n",
    "    best_lstm_model = lstm_grid_result.best_estimator_.model\n",
    "    lstm_accuracy, lstm_precision, lstm_recall = evaluate_model(best_lstm_model, X_test, y_test)\n",
    "\n",
    "    # Evaluate the best CNN model\n",
    "    best_cnn_model = cnn_grid_result.best_estimator_.model\n",
    "    cnn_accuracy, cnn_precision, cnn_recall = evaluate_model(best_cnn_model, X_test, y_test)\n",
    "\n",
    "    # Print evaluation results\n",
    "    print(f\"LSTM Model - Accuracy: {lstm_accuracy}, Precision: {lstm_precision}, Recall: {lstm_recall}\")\n",
    "    print(f\"CNN Model - Accuracy: {cnn_accuracy}, Precision: {cnn_precision}, Recall: {cnn_recall}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10682423,
     "status": "ok",
     "timestamp": 1721631572127,
     "user": {
      "displayName": "Aryaz Zomorodi",
      "userId": "03185736980681493432"
     },
     "user_tz": 420
    },
    "id": "GDZIi2tsmfF2",
    "outputId": "20dcce52-20ce-4f46-c37e-06a0e4d32ec7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping file /content/drive/My Drive/Colab Notebooks/midiclassics/Beethoven/Anhang 14-3.mid due to error: Could not decode key with 3 flats and mode 255\n",
      "Skipping file /content/drive/My Drive/Colab Notebooks/midiclassics/Mozart/Piano Sonatas/Nueva carpeta/K281 Piano Sonata n03 3mov.mid due to error: Could not decode key with 2 flats and mode 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid = os.fork()\n",
      "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 134s 1s/step - loss: 1.0473 - accuracy: 0.6057\n",
      "115/115 [==============================] - 5s 39ms/step - loss: 0.9750 - accuracy: 0.6024\n",
      "Best LSTM Model: 0.6233955121848513 using {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 50, 'optimizer': 'rmsprop', 'units': 64}\n",
      "Best CNN Model: 0.6154825295671835 using {'batch_size': 32, 'dropout_rate': 0.5, 'epochs': 100, 'filters': 64, 'kernel_size': 3, 'optimizer': 'adam'}\n",
      "29/29 [==============================] - 10s 306ms/step\n",
      "29/29 [==============================] - 0s 8ms/step\n",
      "LSTM Model - Accuracy: 0.6335877862595419, Precision: 0.4620305068066262, Recall: 0.6335877862595419\n",
      "CNN Model - Accuracy: 0.6335877862595419, Precision: 0.4718486686719356, Recall: 0.6335877862595419\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pretty_midi\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from google.colab import drive\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Custom wrapper\n",
    "class KerasClassifierCustom:\n",
    "    def __init__(self, build_fn=None, **sk_params):\n",
    "        self.build_fn = build_fn\n",
    "        self.sk_params = sk_params\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, X, y, **fit_params):\n",
    "        self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n",
    "        return self.model.fit(X, y, **fit_params)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "        y_true = np.argmax(y, axis=1)\n",
    "        return accuracy_score(y_true, y_pred_classes)\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        params = self.sk_params.copy()\n",
    "        params['build_fn'] = self.build_fn\n",
    "        return params\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        for key, value in params.items():\n",
    "            if key == \"build_fn\":\n",
    "                self.build_fn = value\n",
    "            else:\n",
    "                self.sk_params[key] = value\n",
    "        return self\n",
    "\n",
    "    def filter_sk_params(self, fn):\n",
    "        res = {}\n",
    "        fn_params = fn.__code__.co_varnames[:fn.__code__.co_argcount]\n",
    "        for name, value in self.sk_params.items():\n",
    "            if name in fn_params:\n",
    "                res[name] = value\n",
    "        return res\n",
    "\n",
    "# Model Building\n",
    "def create_lstm_model(optimizer='adam', units=128, dropout_rate=0.2):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units, input_shape=(max_sequence_length, 1), return_sequences=True))\n",
    "    model.add(LSTM(units))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def create_cnn_model(optimizer='adam', filters=64, kernel_size=3, dropout_rate=0.2):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters, kernel_size=kernel_size, activation='relu', input_shape=(max_sequence_length, 1)))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Function to get MIDI file paths from a directory\n",
    "def get_midi_files_from_directory(directory_path):\n",
    "    midi_files = []\n",
    "    for root, _, files in os.walk(directory_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.mid') or file.endswith('.midi'):\n",
    "                midi_files.append(os.path.join(root, file))\n",
    "    return midi_files\n",
    "\n",
    "# Data Pre-processing\n",
    "def preprocess_data(midi_files):\n",
    "    midi_data = []\n",
    "    for file in midi_files:\n",
    "        try:\n",
    "            midi = pretty_midi.PrettyMIDI(file)\n",
    "            midi_data.append(midi)\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping file {file} due to error: {e}\")\n",
    "    return midi_data\n",
    "\n",
    "# Improved Data Augmentation\n",
    "def augment_data(sequence):\n",
    "    shift = np.random.randint(-5, 6)\n",
    "    stretched_sequence = np.interp(np.linspace(0, len(sequence), len(sequence) * 2), np.arange(len(sequence)), sequence)\n",
    "    return np.clip(np.array(sequence) + shift, 0, 127), np.clip(stretched_sequence, 0, 127)\n",
    "\n",
    "# Feature Extraction\n",
    "def extract_features(midi_data, composer_label):\n",
    "    features = []\n",
    "    labels = []\n",
    "    for midi in midi_data:\n",
    "        if len(midi.instruments) > 0:\n",
    "            notes = midi.instruments[0].notes\n",
    "            pitch_sequence = [note.pitch for note in notes]\n",
    "            features.append(pitch_sequence)\n",
    "            labels.append(composer_label)\n",
    "    return features, labels\n",
    "\n",
    "# Normalize sequences\n",
    "def normalize_sequences(sequences):\n",
    "    return (sequences - np.min(sequences)) / (np.max(sequences) - np.min(sequences))\n",
    "\n",
    "# Model evaluation function\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_true = np.argmax(y_test, axis=1)\n",
    "    accuracy = accuracy_score(y_true, y_pred_classes)\n",
    "    precision = precision_score(y_true, y_pred_classes, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred_classes, average='weighted', zero_division=0)\n",
    "    return accuracy, precision, recall\n",
    "\n",
    "# Main\n",
    "if __name__ == \"__main__\":\n",
    "    # Base directory in Google Drive\n",
    "    base_directory = '/content/drive/My Drive/Colab Notebooks/midiclassics'\n",
    "\n",
    "    # Specify the subdirectories containing MIDI files\n",
    "    composers = {\n",
    "        'Bach': 0,\n",
    "        'Beethoven': 1,\n",
    "        'Chopin': 2,\n",
    "        'Mozart': 3\n",
    "    }\n",
    "\n",
    "    midi_files = []\n",
    "    labels = []\n",
    "\n",
    "    # Get MIDI files from directories and assign labels\n",
    "    for composer, label in composers.items():\n",
    "        composer_directory = os.path.join(base_directory, composer)\n",
    "        composer_files = get_midi_files_from_directory(composer_directory)\n",
    "        if not composer_files:\n",
    "            print(f\"No MIDI files found for {composer}\")\n",
    "        composer_features, composer_labels = extract_features(preprocess_data(composer_files), label)\n",
    "        if not composer_features:\n",
    "            print(f\"No features extracted for {composer}\")\n",
    "        for seq in composer_features:\n",
    "            augmented_seq, stretched_seq = augment_data(seq)\n",
    "            midi_files.append(seq)\n",
    "            midi_files.append(augmented_seq)\n",
    "            midi_files.append(stretched_seq)\n",
    "            labels.extend([label] * 3)\n",
    "\n",
    "    # Pad sequences to ensure they have the same length\n",
    "    max_sequence_length = 1000  # You can adjust this value based on your data\n",
    "    midi_files_padded = pad_sequences(midi_files, maxlen=max_sequence_length, padding='post', truncating='post')\n",
    "\n",
    "    # Normalize sequences\n",
    "    midi_files_padded = normalize_sequences(midi_files_padded)\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    midi_files = np.array(midi_files_padded)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Check if dataset is empty\n",
    "    if midi_files.shape[0] == 0:\n",
    "        raise ValueError(\"No data available after preprocessing. Check your MIDI files and preprocessing steps.\")\n",
    "\n",
    "    # Reshape data to fit model input requirements\n",
    "    X = midi_files.reshape(midi_files.shape[0], midi_files.shape[1], 1)\n",
    "    y = to_categorical(labels, num_classes=4)\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Example usage with LSTM model\n",
    "    lstm_model_custom = KerasClassifierCustom(build_fn=create_lstm_model, epochs=10, batch_size=32, verbose=0)\n",
    "    cnn_model_custom = KerasClassifierCustom(build_fn=create_cnn_model, epochs=10, batch_size=32, verbose=0)\n",
    "\n",
    "    # Hyperparameter tuning for LSTM model\n",
    "    lstm_param_grid = {\n",
    "        'epochs': [50, 100],\n",
    "        'batch_size': [32],\n",
    "        'optimizer': ['rmsprop', 'adam'],\n",
    "        'units': [64, 128],\n",
    "        'dropout_rate': [0.2, 0.5]\n",
    "    }\n",
    "    lstm_grid = GridSearchCV(estimator=lstm_model_custom, param_grid=lstm_param_grid, n_jobs=-1, cv=3, error_score='raise')\n",
    "    lstm_grid_result = lstm_grid.fit(X_train, y_train)\n",
    "\n",
    "    # Hyperparameter tuning for CNN model\n",
    "    cnn_param_grid = {\n",
    "        'epochs': [50, 100],\n",
    "        'batch_size': [32],\n",
    "        'optimizer': ['adam'],\n",
    "        'filters': [32, 64],\n",
    "        'kernel_size': [3, 5],\n",
    "        'dropout_rate': [0.5]\n",
    "    }\n",
    "    cnn_grid = GridSearchCV(estimator=cnn_model_custom, param_grid=cnn_param_grid, n_jobs=-1, cv=3, error_score='raise')\n",
    "    cnn_grid_result = cnn_grid.fit(X_train, y_train)\n",
    "\n",
    "    # Print the best hyperparameters for both models\n",
    "    print(f\"Best LSTM Model: {lstm_grid_result.best_score_} using {lstm_grid_result.best_params_}\")\n",
    "    print(f\"Best CNN Model: {cnn_grid_result.best_score_} using {cnn_grid_result.best_params_}\")\n",
    "\n",
    "    # Evaluate the best LSTM model\n",
    "    best_lstm_model = lstm_grid_result.best_estimator_.model\n",
    "    lstm_accuracy, lstm_precision, lstm_recall = evaluate_model(best_lstm_model, X_test, y_test)\n",
    "\n",
    "    # Evaluate the best CNN model\n",
    "    best_cnn_model = cnn_grid_result.best_estimator_.model\n",
    "    cnn_accuracy, cnn_precision, cnn_recall = evaluate_model(best_cnn_model, X_test, y_test)\n",
    "\n",
    "    # Print evaluation results\n",
    "    print(f\"LSTM Model - Accuracy: {lstm_accuracy}, Precision: {lstm_precision}, Recall: {lstm_recall}\")\n",
    "    print(f\"CNN Model - Accuracy: {cnn_accuracy}, Precision: {cnn_precision}, Recall: {cnn_recall}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 854363,
     "status": "ok",
     "timestamp": 1721945326152,
     "user": {
      "displayName": "Aryaz Zomorodi",
      "userId": "04002852148298941149"
     },
     "user_tz": 420
    },
    "id": "sDq-rVqtsZrF",
    "outputId": "a886eeba-c051-49ae-e6c8-ca9cf8fb3144"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping file /content/drive/My Drive/Colab Notebooks/midiclassics/Beethoven/Anhang 14-3.mid due to error: Could not decode key with 3 flats and mode 255\n",
      "Skipping file /content/drive/My Drive/Colab Notebooks/midiclassics/Mozart/Piano Sonatas/Nueva carpeta/K281 Piano Sonata n03 3mov.mid due to error: Could not decode key with 2 flats and mode 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 12s 62ms/step - loss: 1.0490 - accuracy: 0.6051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 2s 4ms/step - loss: 0.9909 - accuracy: 0.5879\n",
      "Best LSTM Model: 0.599943838744486 using {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 50, 'optimizer': 'rmsprop', 'units': 64}\n",
      "Best CNN Model: 0.603490830191827 using {'batch_size': 32, 'dropout_rate': 0.5, 'epochs': 100, 'filters': 32, 'kernel_size': 5, 'optimizer': 'adam'}\n",
      "29/29 [==============================] - 1s 27ms/step\n",
      "29/29 [==============================] - 0s 3ms/step\n",
      "LSTM Model - Accuracy: 0.6248636859323882, Precision: 0.46579632483147193, Recall: 0.6248636859323882\n",
      "CNN Model - Accuracy: 0.6030534351145038, Precision: 0.5011940719600039, Recall: 0.6030534351145038\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pretty_midi\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from google.colab import drive\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Custom wrapper\n",
    "class KerasClassifierCustom:\n",
    "    def __init__(self, build_fn=None, **sk_params):\n",
    "        self.build_fn = build_fn\n",
    "        self.sk_params = sk_params\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, X, y, **fit_params):\n",
    "        self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n",
    "        return self.model.fit(X, y, **fit_params)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "        y_true = np.argmax(y, axis=1)\n",
    "        return accuracy_score(y_true, y_pred_classes)\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        params = self.sk_params.copy()\n",
    "        params['build_fn'] = self.build_fn\n",
    "        return params\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        for key, value in params.items():\n",
    "            if key == \"build_fn\":\n",
    "                self.build_fn = value\n",
    "            else:\n",
    "                self.sk_params[key] = value\n",
    "        return self\n",
    "\n",
    "    def filter_sk_params(self, fn):\n",
    "        res = {}\n",
    "        fn_params = fn.__code__.co_varnames[:fn.__code__.co_argcount]\n",
    "        for name, value in self.sk_params.items():\n",
    "            if name in fn_params:\n",
    "                res[name] = value\n",
    "        return res\n",
    "\n",
    "# Model Building\n",
    "def create_lstm_model(optimizer='adam', units=128, dropout_rate=0.2):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units, input_shape=(max_sequence_length, 1), return_sequences=True))\n",
    "    model.add(LSTM(units))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def create_cnn_model(optimizer='adam', filters=64, kernel_size=3, dropout_rate=0.2):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters, kernel_size=kernel_size, activation='relu', input_shape=(max_sequence_length, 1)))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Function to get MIDI file paths from a directory\n",
    "def get_midi_files_from_directory(directory_path):\n",
    "    midi_files = []\n",
    "    for root, _, files in os.walk(directory_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.mid') or file.endswith('.midi'):\n",
    "                midi_files.append(os.path.join(root, file))\n",
    "    return midi_files\n",
    "\n",
    "# Data Pre-processing\n",
    "def preprocess_data(midi_files):\n",
    "    midi_data = []\n",
    "    for file in midi_files:\n",
    "        try:\n",
    "            midi = pretty_midi.PrettyMIDI(file)\n",
    "            midi_data.append(midi)\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping file {file} due to error: {e}\")\n",
    "    return midi_data\n",
    "\n",
    "# Improved Data Augmentation\n",
    "def augment_data(sequence):\n",
    "    shift = np.random.randint(-5, 6)\n",
    "    stretched_sequence = np.interp(np.linspace(0, len(sequence), len(sequence) * 2), np.arange(len(sequence)), sequence)\n",
    "    return np.clip(np.array(sequence) + shift, 0, 127), np.clip(stretched_sequence, 0, 127)\n",
    "\n",
    "# Feature Extraction\n",
    "def extract_features(midi_data, composer_label):\n",
    "    features = []\n",
    "    labels = []\n",
    "    for midi in midi_data:\n",
    "        if len(midi.instruments) > 0:\n",
    "            notes = midi.instruments[0].notes\n",
    "            pitch_sequence = [note.pitch for note in notes]\n",
    "            features.append(pitch_sequence)\n",
    "            labels.append(composer_label)\n",
    "    return features, labels\n",
    "\n",
    "# Normalize sequences\n",
    "def normalize_sequences(sequences):\n",
    "    return (sequences - np.min(sequences)) / (np.max(sequences) - np.min(sequences))\n",
    "\n",
    "# Model evaluation function\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_true = np.argmax(y_test, axis=1)\n",
    "    accuracy = accuracy_score(y_true, y_pred_classes)\n",
    "    precision = precision_score(y_true, y_pred_classes, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred_classes, average='weighted', zero_division=0)\n",
    "    return accuracy, precision, recall\n",
    "\n",
    "# Main\n",
    "if __name__ == \"__main__\":\n",
    "    # Base directory in Google Drive\n",
    "    base_directory = '/content/drive/My Drive/Colab Notebooks/midiclassics'\n",
    "\n",
    "    # Specify the subdirectories containing MIDI files\n",
    "    composers = {\n",
    "        'Bach': 0,\n",
    "        'Beethoven': 1,\n",
    "        'Chopin': 2,\n",
    "        'Mozart': 3\n",
    "    }\n",
    "\n",
    "    midi_files = []\n",
    "    labels = []\n",
    "\n",
    "    # Get MIDI files from directories and assign labels\n",
    "    for composer, label in composers.items():\n",
    "        composer_directory = os.path.join(base_directory, composer)\n",
    "        composer_files = get_midi_files_from_directory(composer_directory)\n",
    "        if not composer_files:\n",
    "            print(f\"No MIDI files found for {composer}\")\n",
    "        composer_features, composer_labels = extract_features(preprocess_data(composer_files), label)\n",
    "        if not composer_features:\n",
    "            print(f\"No features extracted for {composer}\")\n",
    "        for seq in composer_features:\n",
    "            augmented_seq, stretched_seq = augment_data(seq)\n",
    "            midi_files.append(seq)\n",
    "            midi_files.append(augmented_seq)\n",
    "            midi_files.append(stretched_seq)\n",
    "            labels.extend([label] * 3)\n",
    "\n",
    "    # Pad sequences to ensure they have the same length\n",
    "    max_sequence_length = 1000  # You can adjust this value based on your data\n",
    "    midi_files_padded = pad_sequences(midi_files, maxlen=max_sequence_length, padding='post', truncating='post')\n",
    "\n",
    "    # Normalize sequences\n",
    "    midi_files_padded = normalize_sequences(midi_files_padded)\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    midi_files = np.array(midi_files_padded)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Check if dataset is empty\n",
    "    if midi_files.shape[0] == 0:\n",
    "        raise ValueError(\"No data available after preprocessing. Check your MIDI files and preprocessing steps.\")\n",
    "\n",
    "    # Reshape data to fit model input requirements\n",
    "    X = midi_files.reshape(midi_files.shape[0], midi_files.shape[1], 1)\n",
    "    y = to_categorical(labels, num_classes=4)\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Example usage with LSTM model\n",
    "    lstm_model_custom = KerasClassifierCustom(build_fn=create_lstm_model, epochs=10, batch_size=32, verbose=0)\n",
    "    cnn_model_custom = KerasClassifierCustom(build_fn=create_cnn_model, epochs=10, batch_size=32, verbose=0)\n",
    "\n",
    "    # Hyperparameter tuning for LSTM model\n",
    "    lstm_param_grid = {\n",
    "        'epochs': [50],\n",
    "        'batch_size': [32],\n",
    "        'optimizer': ['rmsprop'],\n",
    "        'units': [64],\n",
    "        'dropout_rate': [0.2]\n",
    "    }\n",
    "    lstm_grid = GridSearchCV(estimator=lstm_model_custom, param_grid=lstm_param_grid, n_jobs=-1, cv=3, error_score='raise')\n",
    "    lstm_grid_result = lstm_grid.fit(X_train, y_train)\n",
    "\n",
    "    # Hyperparameter tuning for CNN model\n",
    "    cnn_param_grid = {\n",
    "        'epochs': [100],\n",
    "        'batch_size': [32],\n",
    "        'optimizer': ['adam'],\n",
    "        'filters': [32, 64],\n",
    "        'kernel_size': [3, 5],\n",
    "        'dropout_rate': [0.5]\n",
    "    }\n",
    "    cnn_grid = GridSearchCV(estimator=cnn_model_custom, param_grid=cnn_param_grid, n_jobs=-1, cv=3, error_score='raise')\n",
    "    cnn_grid_result = cnn_grid.fit(X_train, y_train)\n",
    "\n",
    "    # Print the best hyperparameters for both models\n",
    "    print(f\"Best LSTM Model: {lstm_grid_result.best_score_} using {lstm_grid_result.best_params_}\")\n",
    "    print(f\"Best CNN Model: {cnn_grid_result.best_score_} using {cnn_grid_result.best_params_}\")\n",
    "\n",
    "    # Evaluate the best LSTM model\n",
    "    best_lstm_model = lstm_grid_result.best_estimator_.model\n",
    "    lstm_accuracy, lstm_precision, lstm_recall = evaluate_model(best_lstm_model, X_test, y_test)\n",
    "\n",
    "    # Evaluate the best CNN model\n",
    "    best_cnn_model = cnn_grid_result.best_estimator_.model\n",
    "    cnn_accuracy, cnn_precision, cnn_recall = evaluate_model(best_cnn_model, X_test, y_test)\n",
    "\n",
    "    # Print evaluation results\n",
    "    print(f\"LSTM Model - Accuracy: {lstm_accuracy}, Precision: {lstm_precision}, Recall: {lstm_recall}\")\n",
    "    print(f\"CNN Model - Accuracy: {cnn_accuracy}, Precision: {cnn_precision}, Recall: {cnn_recall}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5982,
     "status": "ok",
     "timestamp": 1721944444411,
     "user": {
      "displayName": "Aryaz Zomorodi",
      "userId": "04002852148298941149"
     },
     "user_tz": 420
    },
    "id": "ep_39gYx4skX",
    "outputId": "86c2fff2-1f7b-47ff-e1dd-764da71b7cb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pretty_midi\n",
      "  Downloading pretty_midi-0.2.10.tar.gz (5.6 MB)\n",
      "\u001b[?25l     \u001b[90m\u001b[0m \u001b[32m0.0/5.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[91m\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m2.5/5.6 MB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m\u001b[0m\u001b[91m\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m109.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from pretty_midi) (1.25.2)\n",
      "Collecting mido>=1.1.16 (from pretty_midi)\n",
      "  Downloading mido-1.3.2-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from pretty_midi) (1.16.0)\n",
      "Collecting packaging~=23.1 (from mido>=1.1.16->pretty_midi)\n",
      "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Downloading mido-1.3.2-py3-none-any.whl (54 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading packaging-23.2-py3-none-any.whl (53 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: pretty_midi\n",
      "  Building wheel for pretty_midi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pretty_midi: filename=pretty_midi-0.2.10-py3-none-any.whl size=5592288 sha256=f83fe10763e8f95acccaf5895212d38b81e91e6a8330b05100bd58d4b2f0f4ba\n",
      "  Stored in directory: /root/.cache/pip/wheels/cd/a5/30/7b8b7f58709f5150f67f98fde4b891ebf0be9ef07a8af49f25\n",
      "Successfully built pretty_midi\n",
      "Installing collected packages: packaging, mido, pretty_midi\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 24.1\n",
      "    Uninstalling packaging-24.1:\n",
      "      Successfully uninstalled packaging-24.1\n",
      "Successfully installed mido-1.3.2 packaging-23.2 pretty_midi-0.2.10\n"
     ]
    }
   ],
   "source": [
    "!pip install pretty_midi"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
