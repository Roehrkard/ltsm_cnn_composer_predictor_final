{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GwwHW4eJnxwq","executionInfo":{"status":"ok","timestamp":1721607493702,"user_tz":420,"elapsed":336058,"user":{"displayName":"Aryaz Zomorodi","userId":"03185736980681493432"}},"outputId":"01dbd07d-68e5-424e-bb29-8d047ddfb3f6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Skipping file /content/drive/My Drive/Colab Notebooks/midiclassics/Beethoven/Anhang 14-3.mid due to error: Could not decode key with 3 flats and mode 255\n","Skipping file /content/drive/My Drive/Colab Notebooks/midiclassics/Mozart/Piano Sonatas/Nueva carpeta/K281 Piano Sonata n03 3mov.mid due to error: Could not decode key with 2 flats and mode 2\n","Epoch 1/50\n","39/39 [==============================] - 9s 116ms/step - loss: 1.1040 - accuracy: 0.6113 - val_loss: 0.9988 - val_accuracy: 0.6536\n","Epoch 2/50\n","39/39 [==============================] - 3s 65ms/step - loss: 1.1169 - accuracy: 0.5818 - val_loss: 0.9951 - val_accuracy: 0.6536\n","Epoch 3/50\n","39/39 [==============================] - 3s 68ms/step - loss: 1.0067 - accuracy: 0.6056 - val_loss: 1.0234 - val_accuracy: 0.6111\n","Epoch 4/50\n","39/39 [==============================] - 3s 66ms/step - loss: 1.0098 - accuracy: 0.6113 - val_loss: 1.0179 - val_accuracy: 0.5980\n","Epoch 5/50\n","39/39 [==============================] - 3s 84ms/step - loss: 1.0054 - accuracy: 0.5998 - val_loss: 1.0105 - val_accuracy: 0.5719\n","Epoch 6/50\n","39/39 [==============================] - 3s 80ms/step - loss: 0.9975 - accuracy: 0.6244 - val_loss: 1.0052 - val_accuracy: 0.5817\n","Epoch 7/50\n","39/39 [==============================] - 3s 68ms/step - loss: 0.9994 - accuracy: 0.6121 - val_loss: 0.9706 - val_accuracy: 0.6699\n","Epoch 8/50\n","39/39 [==============================] - 3s 68ms/step - loss: 0.9937 - accuracy: 0.6203 - val_loss: 0.9502 - val_accuracy: 0.6797\n","Epoch 9/50\n","39/39 [==============================] - 3s 68ms/step - loss: 0.9942 - accuracy: 0.6137 - val_loss: 0.9708 - val_accuracy: 0.6634\n","Epoch 10/50\n","39/39 [==============================] - 3s 86ms/step - loss: 0.9884 - accuracy: 0.6195 - val_loss: 0.9726 - val_accuracy: 0.6111\n","Epoch 11/50\n","39/39 [==============================] - 3s 76ms/step - loss: 1.0416 - accuracy: 0.5859 - val_loss: 1.0057 - val_accuracy: 0.5784\n","Epoch 12/50\n","39/39 [==============================] - 3s 66ms/step - loss: 0.9939 - accuracy: 0.6097 - val_loss: 0.9562 - val_accuracy: 0.6078\n","Epoch 13/50\n","39/39 [==============================] - 3s 66ms/step - loss: 0.9664 - accuracy: 0.6203 - val_loss: 0.9949 - val_accuracy: 0.6013\n","Epoch 14/50\n","39/39 [==============================] - 3s 66ms/step - loss: 0.9868 - accuracy: 0.6350 - val_loss: 0.9776 - val_accuracy: 0.6242\n","Epoch 15/50\n","39/39 [==============================] - 3s 84ms/step - loss: 0.9793 - accuracy: 0.6326 - val_loss: 0.9477 - val_accuracy: 0.6209\n","Epoch 16/50\n","39/39 [==============================] - 3s 77ms/step - loss: 0.9546 - accuracy: 0.6318 - val_loss: 0.9615 - val_accuracy: 0.5915\n","Epoch 17/50\n","39/39 [==============================] - 3s 65ms/step - loss: 0.9461 - accuracy: 0.6293 - val_loss: 0.9595 - val_accuracy: 0.5980\n","Epoch 18/50\n","39/39 [==============================] - 3s 71ms/step - loss: 0.9249 - accuracy: 0.6375 - val_loss: 0.8835 - val_accuracy: 0.6340\n","Epoch 19/50\n","39/39 [==============================] - 3s 67ms/step - loss: 0.9198 - accuracy: 0.6318 - val_loss: 0.8911 - val_accuracy: 0.6634\n","Epoch 20/50\n","39/39 [==============================] - 3s 89ms/step - loss: 0.9481 - accuracy: 0.6342 - val_loss: 0.8649 - val_accuracy: 0.6144\n","Epoch 21/50\n","39/39 [==============================] - 3s 73ms/step - loss: 0.9057 - accuracy: 0.6391 - val_loss: 0.8500 - val_accuracy: 0.6275\n","Epoch 22/50\n","39/39 [==============================] - 3s 66ms/step - loss: 0.8947 - accuracy: 0.6367 - val_loss: 0.8570 - val_accuracy: 0.6405\n","Epoch 23/50\n","39/39 [==============================] - 3s 65ms/step - loss: 0.9007 - accuracy: 0.6334 - val_loss: 0.9207 - val_accuracy: 0.5752\n","Epoch 24/50\n","39/39 [==============================] - 2s 64ms/step - loss: 0.9031 - accuracy: 0.6350 - val_loss: 0.9157 - val_accuracy: 0.6111\n","Epoch 25/50\n","39/39 [==============================] - 3s 86ms/step - loss: 0.8928 - accuracy: 0.6375 - val_loss: 0.8858 - val_accuracy: 0.6078\n","Epoch 26/50\n","39/39 [==============================] - 3s 73ms/step - loss: 0.8820 - accuracy: 0.6358 - val_loss: 0.8668 - val_accuracy: 0.6340\n","Epoch 27/50\n","39/39 [==============================] - 3s 65ms/step - loss: 0.8912 - accuracy: 0.6424 - val_loss: 0.8634 - val_accuracy: 0.6275\n","Epoch 28/50\n","39/39 [==============================] - 3s 65ms/step - loss: 0.8998 - accuracy: 0.6399 - val_loss: 0.8480 - val_accuracy: 0.6634\n","Epoch 29/50\n","39/39 [==============================] - 3s 68ms/step - loss: 0.8843 - accuracy: 0.6424 - val_loss: 0.8534 - val_accuracy: 0.6340\n","Epoch 30/50\n","39/39 [==============================] - 4s 92ms/step - loss: 0.8794 - accuracy: 0.6432 - val_loss: 0.8484 - val_accuracy: 0.6307\n","Epoch 31/50\n","39/39 [==============================] - 3s 71ms/step - loss: 0.8861 - accuracy: 0.6465 - val_loss: 0.8556 - val_accuracy: 0.6275\n","Epoch 32/50\n","39/39 [==============================] - 3s 65ms/step - loss: 0.8801 - accuracy: 0.6473 - val_loss: 0.8570 - val_accuracy: 0.6503\n","Epoch 33/50\n","39/39 [==============================] - 3s 65ms/step - loss: 0.9034 - accuracy: 0.6383 - val_loss: 0.8609 - val_accuracy: 0.6601\n","Epoch 34/50\n","39/39 [==============================] - 3s 66ms/step - loss: 0.8801 - accuracy: 0.6522 - val_loss: 0.8459 - val_accuracy: 0.6601\n","Epoch 35/50\n","39/39 [==============================] - 3s 87ms/step - loss: 0.8809 - accuracy: 0.6473 - val_loss: 0.8756 - val_accuracy: 0.6144\n","Epoch 36/50\n","39/39 [==============================] - 3s 77ms/step - loss: 0.8751 - accuracy: 0.6465 - val_loss: 0.8641 - val_accuracy: 0.6242\n","Epoch 37/50\n","39/39 [==============================] - 3s 65ms/step - loss: 0.8723 - accuracy: 0.6489 - val_loss: 0.8467 - val_accuracy: 0.6569\n","Epoch 38/50\n","39/39 [==============================] - 3s 68ms/step - loss: 0.8705 - accuracy: 0.6457 - val_loss: 0.8395 - val_accuracy: 0.6667\n","Epoch 39/50\n","39/39 [==============================] - 3s 71ms/step - loss: 0.8755 - accuracy: 0.6416 - val_loss: 0.8601 - val_accuracy: 0.6569\n","Epoch 40/50\n","39/39 [==============================] - 3s 90ms/step - loss: 0.8698 - accuracy: 0.6448 - val_loss: 0.8416 - val_accuracy: 0.6667\n","Epoch 41/50\n","39/39 [==============================] - 3s 78ms/step - loss: 0.8568 - accuracy: 0.6547 - val_loss: 0.8797 - val_accuracy: 0.6503\n","Epoch 42/50\n","39/39 [==============================] - 3s 68ms/step - loss: 0.8986 - accuracy: 0.6268 - val_loss: 0.8889 - val_accuracy: 0.6013\n","Epoch 43/50\n","39/39 [==============================] - 3s 68ms/step - loss: 0.8763 - accuracy: 0.6498 - val_loss: 0.8340 - val_accuracy: 0.6699\n","Epoch 44/50\n","39/39 [==============================] - 3s 68ms/step - loss: 0.8699 - accuracy: 0.6506 - val_loss: 0.8485 - val_accuracy: 0.6667\n","Epoch 45/50\n","39/39 [==============================] - 3s 89ms/step - loss: 0.8716 - accuracy: 0.6473 - val_loss: 0.8346 - val_accuracy: 0.6667\n","Epoch 46/50\n","39/39 [==============================] - 3s 73ms/step - loss: 0.8622 - accuracy: 0.6547 - val_loss: 0.8203 - val_accuracy: 0.6699\n","Epoch 47/50\n","39/39 [==============================] - 3s 71ms/step - loss: 0.8865 - accuracy: 0.6457 - val_loss: 0.8428 - val_accuracy: 0.6536\n","Epoch 48/50\n","39/39 [==============================] - 3s 68ms/step - loss: 0.8704 - accuracy: 0.6465 - val_loss: 0.9141 - val_accuracy: 0.6078\n","Epoch 49/50\n","39/39 [==============================] - 3s 69ms/step - loss: 0.8783 - accuracy: 0.6375 - val_loss: 0.8865 - val_accuracy: 0.6601\n","Epoch 50/50\n","39/39 [==============================] - 4s 105ms/step - loss: 0.8948 - accuracy: 0.6473 - val_loss: 0.9158 - val_accuracy: 0.6307\n","Epoch 1/50\n","39/39 [==============================] - 2s 12ms/step - loss: 30.7389 - accuracy: 0.5041 - val_loss: 10.5597 - val_accuracy: 0.6144\n","Epoch 2/50\n","39/39 [==============================] - 0s 6ms/step - loss: 7.3558 - accuracy: 0.5687 - val_loss: 8.6413 - val_accuracy: 0.6111\n","Epoch 3/50\n","39/39 [==============================] - 0s 5ms/step - loss: 4.7793 - accuracy: 0.5900 - val_loss: 7.6406 - val_accuracy: 0.5261\n","Epoch 4/50\n","39/39 [==============================] - 0s 6ms/step - loss: 2.7230 - accuracy: 0.6391 - val_loss: 3.3881 - val_accuracy: 0.6601\n","Epoch 5/50\n","39/39 [==============================] - 0s 6ms/step - loss: 1.5049 - accuracy: 0.7005 - val_loss: 2.6837 - val_accuracy: 0.5261\n","Epoch 6/50\n","39/39 [==============================] - 0s 5ms/step - loss: 0.6065 - accuracy: 0.7913 - val_loss: 1.9185 - val_accuracy: 0.5588\n","Epoch 7/50\n","39/39 [==============================] - 0s 6ms/step - loss: 0.3156 - accuracy: 0.8609 - val_loss: 1.7619 - val_accuracy: 0.5915\n","Epoch 8/50\n","39/39 [==============================] - 0s 6ms/step - loss: 0.2626 - accuracy: 0.8903 - val_loss: 2.0708 - val_accuracy: 0.5556\n","Epoch 9/50\n","39/39 [==============================] - 0s 6ms/step - loss: 0.2328 - accuracy: 0.9034 - val_loss: 2.2256 - val_accuracy: 0.5588\n","Epoch 10/50\n","39/39 [==============================] - 0s 5ms/step - loss: 0.1862 - accuracy: 0.9403 - val_loss: 1.9101 - val_accuracy: 0.5850\n","Epoch 11/50\n","39/39 [==============================] - 0s 5ms/step - loss: 0.1471 - accuracy: 0.9484 - val_loss: 2.0381 - val_accuracy: 0.5458\n","Epoch 12/50\n","39/39 [==============================] - 0s 5ms/step - loss: 0.1259 - accuracy: 0.9558 - val_loss: 2.1345 - val_accuracy: 0.5523\n","Epoch 13/50\n","39/39 [==============================] - 0s 6ms/step - loss: 0.1020 - accuracy: 0.9714 - val_loss: 2.0616 - val_accuracy: 0.5882\n","Epoch 14/50\n","39/39 [==============================] - 0s 7ms/step - loss: 0.0899 - accuracy: 0.9705 - val_loss: 2.1261 - val_accuracy: 0.5458\n","Epoch 15/50\n","39/39 [==============================] - 0s 5ms/step - loss: 0.0828 - accuracy: 0.9763 - val_loss: 2.1720 - val_accuracy: 0.5686\n","Epoch 16/50\n","39/39 [==============================] - 0s 5ms/step - loss: 0.0699 - accuracy: 0.9828 - val_loss: 2.3144 - val_accuracy: 0.5784\n","Epoch 17/50\n","39/39 [==============================] - 0s 6ms/step - loss: 0.0610 - accuracy: 0.9845 - val_loss: 2.3512 - val_accuracy: 0.5490\n","Epoch 18/50\n","39/39 [==============================] - 0s 5ms/step - loss: 0.0573 - accuracy: 0.9828 - val_loss: 2.2882 - val_accuracy: 0.5523\n","Epoch 19/50\n","39/39 [==============================] - 0s 5ms/step - loss: 0.0516 - accuracy: 0.9877 - val_loss: 2.3617 - val_accuracy: 0.5556\n","Epoch 20/50\n","39/39 [==============================] - 0s 5ms/step - loss: 0.0484 - accuracy: 0.9861 - val_loss: 2.3558 - val_accuracy: 0.5588\n","Epoch 21/50\n","39/39 [==============================] - 0s 6ms/step - loss: 0.0436 - accuracy: 0.9885 - val_loss: 2.4822 - val_accuracy: 0.5556\n","Epoch 22/50\n","39/39 [==============================] - 0s 6ms/step - loss: 0.0354 - accuracy: 0.9951 - val_loss: 2.4161 - val_accuracy: 0.5621\n","Epoch 23/50\n","39/39 [==============================] - 0s 6ms/step - loss: 0.0407 - accuracy: 0.9894 - val_loss: 2.4916 - val_accuracy: 0.5523\n","Epoch 24/50\n","39/39 [==============================] - 0s 6ms/step - loss: 0.0339 - accuracy: 0.9926 - val_loss: 2.5461 - val_accuracy: 0.5425\n","Epoch 25/50\n","39/39 [==============================] - 0s 6ms/step - loss: 0.0306 - accuracy: 0.9943 - val_loss: 2.4414 - val_accuracy: 0.5752\n","Epoch 26/50\n","39/39 [==============================] - 0s 7ms/step - loss: 0.0299 - accuracy: 0.9926 - val_loss: 2.6054 - val_accuracy: 0.5458\n","Epoch 27/50\n","39/39 [==============================] - 0s 5ms/step - loss: 0.0291 - accuracy: 0.9935 - val_loss: 2.4422 - val_accuracy: 0.5752\n","Epoch 28/50\n","39/39 [==============================] - 0s 5ms/step - loss: 0.0263 - accuracy: 0.9943 - val_loss: 2.8163 - val_accuracy: 0.5458\n","Epoch 29/50\n","39/39 [==============================] - 0s 5ms/step - loss: 0.0240 - accuracy: 0.9959 - val_loss: 2.8163 - val_accuracy: 0.5719\n","Epoch 30/50\n","39/39 [==============================] - 0s 5ms/step - loss: 0.0226 - accuracy: 0.9951 - val_loss: 2.6902 - val_accuracy: 0.5458\n","Epoch 31/50\n","39/39 [==============================] - 0s 6ms/step - loss: 0.0185 - accuracy: 0.9975 - val_loss: 3.5668 - val_accuracy: 0.5458\n","Epoch 32/50\n","39/39 [==============================] - 0s 6ms/step - loss: 0.1892 - accuracy: 0.9345 - val_loss: 2.5203 - val_accuracy: 0.5784\n","Epoch 33/50\n","39/39 [==============================] - 0s 5ms/step - loss: 0.0814 - accuracy: 0.9722 - val_loss: 2.9367 - val_accuracy: 0.5490\n","Epoch 34/50\n","39/39 [==============================] - 0s 6ms/step - loss: 0.0436 - accuracy: 0.9894 - val_loss: 2.7799 - val_accuracy: 0.5621\n","Epoch 35/50\n","39/39 [==============================] - 0s 7ms/step - loss: 0.0289 - accuracy: 0.9943 - val_loss: 2.8204 - val_accuracy: 0.5490\n","Epoch 36/50\n","39/39 [==============================] - 0s 8ms/step - loss: 0.0323 - accuracy: 0.9918 - val_loss: 3.0015 - val_accuracy: 0.5556\n","Epoch 37/50\n","39/39 [==============================] - 0s 8ms/step - loss: 0.0204 - accuracy: 0.9975 - val_loss: 2.9880 - val_accuracy: 0.5458\n","Epoch 38/50\n","39/39 [==============================] - 0s 7ms/step - loss: 0.0169 - accuracy: 0.9984 - val_loss: 3.0913 - val_accuracy: 0.5523\n","Epoch 39/50\n","39/39 [==============================] - 0s 8ms/step - loss: 0.0168 - accuracy: 0.9975 - val_loss: 3.0109 - val_accuracy: 0.5621\n","Epoch 40/50\n","39/39 [==============================] - 0s 7ms/step - loss: 0.0154 - accuracy: 0.9984 - val_loss: 2.9850 - val_accuracy: 0.5588\n","Epoch 41/50\n","39/39 [==============================] - 0s 7ms/step - loss: 0.0135 - accuracy: 0.9992 - val_loss: 3.0217 - val_accuracy: 0.5523\n","Epoch 42/50\n","39/39 [==============================] - 0s 8ms/step - loss: 0.0163 - accuracy: 0.9975 - val_loss: 3.0163 - val_accuracy: 0.5359\n","Epoch 43/50\n","39/39 [==============================] - 0s 8ms/step - loss: 0.0156 - accuracy: 0.9992 - val_loss: 3.0454 - val_accuracy: 0.5458\n","Epoch 44/50\n","39/39 [==============================] - 0s 7ms/step - loss: 0.0129 - accuracy: 0.9992 - val_loss: 3.0302 - val_accuracy: 0.5458\n","Epoch 45/50\n","39/39 [==============================] - 0s 8ms/step - loss: 0.0125 - accuracy: 0.9984 - val_loss: 3.0685 - val_accuracy: 0.5458\n","Epoch 46/50\n","39/39 [==============================] - 0s 9ms/step - loss: 0.0127 - accuracy: 0.9992 - val_loss: 3.1084 - val_accuracy: 0.5523\n","Epoch 47/50\n","39/39 [==============================] - 0s 7ms/step - loss: 0.0113 - accuracy: 0.9992 - val_loss: 3.1724 - val_accuracy: 0.5392\n","Epoch 48/50\n","39/39 [==============================] - 0s 6ms/step - loss: 0.0114 - accuracy: 0.9975 - val_loss: 3.2217 - val_accuracy: 0.5294\n","Epoch 49/50\n","39/39 [==============================] - 0s 6ms/step - loss: 0.0240 - accuracy: 0.9910 - val_loss: 3.7305 - val_accuracy: 0.5621\n","Epoch 50/50\n","39/39 [==============================] - 0s 5ms/step - loss: 0.0188 - accuracy: 0.9959 - val_loss: 3.0871 - val_accuracy: 0.5425\n","10/10 [==============================] - 1s 39ms/step\n","10/10 [==============================] - 0s 2ms/step\n","LSTM Model - Accuracy: 0.630718954248366, Precision: 0.6361009732360097, Recall: 0.36927045875558456\n","CNN Model - Accuracy: 0.5424836601307189, Precision: 0.3990531885268727, Recall: 0.3935845047401111\n"]}],"source":["# Import necessary libraries\n","import os\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Conv1D, MaxPooling1D, Flatten, Dense\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_score, recall_score\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","# Install pretty_midi\n","# !pip install pretty_midi\n","\n","import pretty_midi\n","\n","# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Data Pre-processing\n","def preprocess_data(midi_files):\n","    midi_data = []\n","    for file in midi_files:\n","        try:\n","            midi = pretty_midi.PrettyMIDI(file)\n","            midi_data.append(midi)\n","        except Exception as e:\n","            print(f\"Skipping file {file} due to error: {e}\")\n","    # Apply data augmentation techniques if necessary\n","    return midi_data\n","\n","# Feature Extraction\n","def extract_features(midi_data, composer_label):\n","    features = []\n","    labels = []\n","    for midi in midi_data:\n","        # Extract features such as notes, chords, tempo\n","        notes = midi.instruments[0].notes\n","        pitch_sequence = [note.pitch for note in notes]  # Example feature: pitch of notes\n","        features.append(pitch_sequence)\n","        labels.append(composer_label)\n","    return features, labels\n","\n","# Model Building\n","def build_lstm_model(input_shape):\n","    model = Sequential()\n","    model.add(LSTM(128, input_shape=input_shape, return_sequences=True))\n","    model.add(LSTM(128))\n","    model.add(Dense(4, activation='softmax'))\n","    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","    return model\n","\n","def build_cnn_model(input_shape):\n","    model = Sequential()\n","    model.add(Conv1D(64, kernel_size=3, activation='relu', input_shape=input_shape))\n","    model.add(MaxPooling1D(pool_size=2))\n","    model.add(Flatten())\n","    model.add(Dense(4, activation='softmax'))\n","    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","    return model\n","\n","# Model Training\n","def train_model(model, X_train, y_train, X_val, y_val):\n","    history = model.fit(X_train, y_train, epochs=50, validation_data=(X_val, y_val))\n","    return history\n","\n","# Model Evaluation\n","def evaluate_model(model, X_test, y_test):\n","    y_pred = model.predict(X_test)\n","    y_pred_classes = np.argmax(y_pred, axis=1)\n","    y_true = np.argmax(y_test, axis=1)\n","    accuracy = accuracy_score(y_true, y_pred_classes)\n","    precision = precision_score(y_true, y_pred_classes, average='macro')\n","    recall = recall_score(y_true, y_pred_classes, average='macro')\n","    return accuracy, precision, recall\n","\n","# Function to get MIDI file paths from a directory\n","def get_midi_files_from_directory(directory_path):\n","    midi_files = []\n","    for root, _, files in os.walk(directory_path):\n","        for file in files:\n","            if file.endswith('.mid') or file.endswith('.midi'):\n","                midi_files.append(os.path.join(root, file))\n","    return midi_files\n","\n","# Main\n","if __name__ == \"__main__\":\n","    # Base directory in Google Drive\n","    base_directory = '/content/drive/My Drive/Colab Notebooks/midiclassics'\n","\n","    # Specify the subdirectories containing MIDI files\n","    composers = {\n","        'Bach': 0,\n","        'Beethoven': 1,\n","        'Chopin': 2,\n","        'Mozart': 3\n","    }\n","\n","    midi_files = []\n","    labels = []\n","\n","    # Get MIDI files from directories and assign labels\n","    for composer, label in composers.items():\n","        composer_directory = os.path.join(base_directory, composer)\n","        composer_files = get_midi_files_from_directory(composer_directory)\n","        composer_features, composer_labels = extract_features(preprocess_data(composer_files), label)\n","        midi_files.extend(composer_features)\n","        labels.extend(composer_labels)\n","\n","    # Pad sequences to ensure they have the same length\n","    max_sequence_length = 1000  # You can adjust this value based on your data\n","    midi_files_padded = pad_sequences(midi_files, maxlen=max_sequence_length, padding='post', truncating='post')\n","\n","    # Convert lists to numpy arrays\n","    midi_files = np.array(midi_files_padded)\n","    labels = np.array(labels)\n","\n","    # Reshape data to fit model input requirements\n","    X = midi_files.reshape(midi_files.shape[0], midi_files.shape[1], 1)\n","    y = to_categorical(labels, num_classes=4)\n","\n","    # Split data\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","    # Build and train models\n","    lstm_model = build_lstm_model((X_train.shape[1], 1))\n","    cnn_model = build_cnn_model((X_train.shape[1], 1))\n","    lstm_history = train_model(lstm_model, X_train, y_train, X_test, y_test)\n","    cnn_history = train_model(cnn_model, X_train, y_train, X_test, y_test)\n","\n","    # Evaluate models\n","    lstm_accuracy, lstm_precision, lstm_recall = evaluate_model(lstm_model, X_test, y_test)\n","    cnn_accuracy, cnn_precision, cnn_recall = evaluate_model(cnn_model, X_test, y_test)\n","\n","    # Print evaluation results\n","    print(f\"LSTM Model - Accuracy: {lstm_accuracy}, Precision: {lstm_precision}, Recall: {lstm_recall}\")\n","    print(f\"CNN Model - Accuracy: {cnn_accuracy}, Precision: {cnn_precision}, Recall: {cnn_recall}\")\n"]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import pandas as pd\n","import pretty_midi\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.metrics import accuracy_score, precision_score, recall_score\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Custom wrapper\n","class KerasClassifierCustom:\n","    def __init__(self, build_fn=None, **sk_params):\n","        self.build_fn = build_fn\n","        self.sk_params = sk_params\n","        self.model = None\n","\n","    def fit(self, X, y, **fit_params):\n","        self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n","        return self.model.fit(X, y, **fit_params)\n","\n","    def predict(self, X):\n","        return self.model.predict(X)\n","\n","    def score(self, X, y):\n","        y_pred = self.predict(X)\n","        y_pred_classes = np.argmax(y_pred, axis=1)\n","        y_true = np.argmax(y, axis=1)\n","        return accuracy_score(y_true, y_pred_classes)\n","\n","    def get_params(self, deep=True):\n","        params = self.sk_params.copy()\n","        params['build_fn'] = self.build_fn\n","        return params\n","\n","    def set_params(self, **params):\n","        for key, value in params.items():\n","            if key == \"build_fn\":\n","                self.build_fn = value\n","            else:\n","                self.sk_params[key] = value\n","        return self\n","\n","    def filter_sk_params(self, fn):\n","        res = {}\n","        fn_params = fn.__code__.co_varnames[:fn.__code__.co_argcount]\n","        for name, value in self.sk_params.items():\n","            if name in fn_params:\n","                res[name] = value\n","        return res\n","\n","# Model Building\n","def create_lstm_model(optimizer='adam', units=128, dropout_rate=0.2):\n","    model = Sequential()\n","    model.add(LSTM(units, input_shape=(max_sequence_length, 1), return_sequences=True))\n","    model.add(LSTM(units))\n","    model.add(Dropout(dropout_rate))\n","    model.add(Dense(4, activation='softmax'))\n","    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n","    return model\n","\n","def create_cnn_model(optimizer='adam', filters=64, kernel_size=3, dropout_rate=0.2):\n","    model = Sequential()\n","    model.add(Conv1D(filters, kernel_size=kernel_size, activation='relu', input_shape=(max_sequence_length, 1)))\n","    model.add(MaxPooling1D(pool_size=2))\n","    model.add(Flatten())\n","    model.add(Dropout(dropout_rate))\n","    model.add(Dense(4, activation='softmax'))\n","    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n","    return model\n","\n","# Function to get MIDI file paths from a directory\n","def get_midi_files_from_directory(directory_path):\n","    midi_files = []\n","    for root, _, files in os.walk(directory_path):\n","        for file in files:\n","            if file.endswith('.mid') or file.endswith('.midi'):\n","                midi_files.append(os.path.join(root, file))\n","    return midi_files\n","\n","# Data Pre-processing\n","def preprocess_data(midi_files):\n","    midi_data = []\n","    for file in midi_files:\n","        try:\n","            midi = pretty_midi.PrettyMIDI(file)\n","            midi_data.append(midi)\n","        except Exception as e:\n","            print(f\"Skipping file {file} due to error: {e}\")\n","    return midi_data\n","\n","# Data Augmentation\n","def augment_data(sequence):\n","    shift = np.random.randint(-5, 6)\n","    return np.clip(np.array(sequence) + shift, 0, 127)\n","\n","# Feature Extraction\n","def extract_features(midi_data, composer_label):\n","    features = []\n","    labels = []\n","    for midi in midi_data:\n","        if len(midi.instruments) > 0:\n","            notes = midi.instruments[0].notes\n","            pitch_sequence = [note.pitch for note in notes]\n","            features.append(pitch_sequence)\n","            labels.append(composer_label)\n","    return features, labels\n","\n","# Model evaluation function\n","def evaluate_model(model, X_test, y_test):\n","    y_pred = model.predict(X_test)\n","    y_pred_classes = np.argmax(y_pred, axis=1)\n","    y_true = np.argmax(y_test, axis=1)\n","    accuracy = accuracy_score(y_true, y_pred_classes)\n","    precision = precision_score(y_true, y_pred_classes, average='weighted', zero_division=0)\n","    recall = recall_score(y_true, y_pred_classes, average='weighted', zero_division=0)\n","    return accuracy, precision, recall\n","\n","# Main\n","if __name__ == \"__main__\":\n","    # Base directory in Google Drive\n","    base_directory = '/content/drive/My Drive/Colab Notebooks/midiclassics'\n","\n","    # Specify the subdirectories containing MIDI files\n","    composers = {\n","        'Bach': 0,\n","        'Beethoven': 1,\n","        'Chopin': 2,\n","        'Mozart': 3\n","    }\n","\n","    midi_files = []\n","    labels = []\n","\n","    # Get MIDI files from directories and assign labels\n","    for composer, label in composers.items():\n","        composer_directory = os.path.join(base_directory, composer)\n","        composer_files = get_midi_files_from_directory(composer_directory)\n","        if not composer_files:\n","            print(f\"No MIDI files found for {composer}\")\n","        composer_features, composer_labels = extract_features(preprocess_data(composer_files), label)\n","        if not composer_features:\n","            print(f\"No features extracted for {composer}\")\n","        augmented_features = [augment_data(seq) for seq in composer_features]\n","        midi_files.extend(composer_features)\n","        midi_files.extend(augmented_features)\n","        labels.extend(composer_labels)\n","        labels.extend(composer_labels)  # Augmented data has the same labels\n","\n","    # Pad sequences to ensure they have the same length\n","    max_sequence_length = 1000  # You can adjust this value based on your data\n","    midi_files_padded = pad_sequences(midi_files, maxlen=max_sequence_length, padding='post', truncating='post')\n","\n","    # Convert lists to numpy arrays\n","    midi_files = np.array(midi_files_padded)\n","    labels = np.array(labels)\n","\n","    # Check if dataset is empty\n","    if midi_files.shape[0] == 0:\n","        raise ValueError(\"No data available after preprocessing. Check your MIDI files and preprocessing steps.\")\n","\n","    # Reshape data to fit model input requirements\n","    X = midi_files.reshape(midi_files.shape[0], midi_files.shape[1], 1)\n","    y = to_categorical(labels, num_classes=4)\n","\n","    # Split data\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","    # Example usage with LSTM model\n","    lstm_model_custom = KerasClassifierCustom(build_fn=create_lstm_model, epochs=10, batch_size=32, verbose=0)\n","    cnn_model_custom = KerasClassifierCustom(build_fn=create_cnn_model, epochs=10, batch_size=32, verbose=0)\n","\n","    # Hyperparameter tuning for LSTM model\n","    lstm_param_grid = {\n","        'epochs': [50],\n","        'batch_size': [32],\n","        'optimizer': ['rmsprop'],\n","        'units': [64],\n","        'dropout_rate': [0.2]\n","    }\n","    lstm_grid = GridSearchCV(estimator=lstm_model_custom, param_grid=lstm_param_grid, n_jobs=-1, cv=3, error_score='raise')\n","    lstm_grid_result = lstm_grid.fit(X_train, y_train)\n","\n","    # Hyperparameter tuning for CNN model\n","    cnn_param_grid = {\n","        'epochs': [100],\n","        'batch_size': [32],\n","        'optimizer': ['adam'],\n","        'filters': [32],\n","        'kernel_size': [3],\n","        'dropout_rate': [0.5]\n","    }\n","    cnn_grid = GridSearchCV(estimator=cnn_model_custom, param_grid=cnn_param_grid, n_jobs=-1, cv=3, error_score='raise')\n","    cnn_grid_result = cnn_grid.fit(X_train, y_train)\n","\n","    # Print the best hyperparameters for both models\n","    print(f\"Best LSTM Model: {lstm_grid_result.best_score_} using {lstm_grid_result.best_params_}\")\n","    print(f\"Best CNN Model: {cnn_grid_result.best_score_} using {cnn_grid_result.best_params_}\")\n","\n","    # Evaluate the best LSTM model\n","    best_lstm_model = lstm_grid_result.best_estimator_.model\n","    lstm_accuracy, lstm_precision, lstm_recall = evaluate_model(best_lstm_model, X_test, y_test)\n","\n","    # Evaluate the best CNN model\n","    best_cnn_model = cnn_grid_result.best_estimator_.model\n","    cnn_accuracy, cnn_precision, cnn_recall = evaluate_model(best_cnn_model, X_test, y_test)\n","\n","    # Print evaluation results\n","    print(f\"LSTM Model - Accuracy: {lstm_accuracy}, Precision: {lstm_precision}, Recall: {lstm_recall}\")\n","    print(f\"CNN Model - Accuracy: {cnn_accuracy}, Precision: {cnn_precision}, Recall: {cnn_recall}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wSqe4N3R9o5p","executionInfo":{"status":"ok","timestamp":1721619426518,"user_tz":420,"elapsed":630681,"user":{"displayName":"Aryaz Zomorodi","userId":"03185736980681493432"}},"outputId":"671a80b6-bdf3-43b8-94d2-21bfb120836a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Skipping file /content/drive/My Drive/Colab Notebooks/midiclassics/Beethoven/Anhang 14-3.mid due to error: Could not decode key with 3 flats and mode 255\n","Skipping file /content/drive/My Drive/Colab Notebooks/midiclassics/Mozart/Piano Sonatas/Nueva carpeta/K281 Piano Sonata n03 3mov.mid due to error: Could not decode key with 2 flats and mode 2\n","77/77 [==============================] - 91s 1s/step - loss: 1.0465 - accuracy: 0.6133\n","77/77 [==============================] - 3s 21ms/step - loss: 12.8485 - accuracy: 0.5442\n","Best LSTM Model: 0.6223356094521738 using {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 50, 'optimizer': 'rmsprop', 'units': 64}\n","Best CNN Model: 0.5716289072117293 using {'batch_size': 32, 'dropout_rate': 0.5, 'epochs': 100, 'filters': 32, 'kernel_size': 3, 'optimizer': 'adam'}\n","20/20 [==============================] - 6s 255ms/step\n","20/20 [==============================] - 0s 10ms/step\n","LSTM Model - Accuracy: 0.6225490196078431, Precision: 0.510877866238998, Recall: 0.6225490196078431\n","CNN Model - Accuracy: 0.49836601307189543, Precision: 0.6196943998305922, Recall: 0.49836601307189543\n"]}]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import pandas as pd\n","import pretty_midi\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.metrics import accuracy_score, precision_score, recall_score\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Custom wrapper\n","class KerasClassifierCustom:\n","    def __init__(self, build_fn=None, **sk_params):\n","        self.build_fn = build_fn\n","        self.sk_params = sk_params\n","        self.model = None\n","\n","    def fit(self, X, y, **fit_params):\n","        self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n","        return self.model.fit(X, y, **fit_params)\n","\n","    def predict(self, X):\n","        return self.model.predict(X)\n","\n","    def score(self, X, y):\n","        y_pred = self.predict(X)\n","        y_pred_classes = np.argmax(y_pred, axis=1)\n","        y_true = np.argmax(y, axis=1)\n","        return accuracy_score(y_true, y_pred_classes)\n","\n","    def get_params(self, deep=True):\n","        params = self.sk_params.copy()\n","        params['build_fn'] = self.build_fn\n","        return params\n","\n","    def set_params(self, **params):\n","        for key, value in params.items():\n","            if key == \"build_fn\":\n","                self.build_fn = value\n","            else:\n","                self.sk_params[key] = value\n","        return self\n","\n","    def filter_sk_params(self, fn):\n","        res = {}\n","        fn_params = fn.__code__.co_varnames[:fn.__code__.co_argcount]\n","        for name, value in self.sk_params.items():\n","            if name in fn_params:\n","                res[name] = value\n","        return res\n","\n","# Model Building\n","def create_lstm_model(optimizer='adam', units=128, dropout_rate=0.2):\n","    model = Sequential()\n","    model.add(LSTM(units, input_shape=(max_sequence_length, 1), return_sequences=True))\n","    model.add(LSTM(units))\n","    model.add(Dropout(dropout_rate))\n","    model.add(Dense(4, activation='softmax'))\n","    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n","    return model\n","\n","def create_cnn_model(optimizer='adam', filters=64, kernel_size=3, dropout_rate=0.2):\n","    model = Sequential()\n","    model.add(Conv1D(filters, kernel_size=kernel_size, activation='relu', input_shape=(max_sequence_length, 1)))\n","    model.add(MaxPooling1D(pool_size=2))\n","    model.add(Flatten())\n","    model.add(Dropout(dropout_rate))\n","    model.add(Dense(4, activation='softmax'))\n","    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n","    return model\n","\n","# Function to get MIDI file paths from a directory\n","def get_midi_files_from_directory(directory_path):\n","    midi_files = []\n","    for root, _, files in os.walk(directory_path):\n","        for file in files:\n","            if file.endswith('.mid') or file.endswith('.midi'):\n","                midi_files.append(os.path.join(root, file))\n","    return midi_files\n","\n","# Data Pre-processing\n","def preprocess_data(midi_files):\n","    midi_data = []\n","    for file in midi_files:\n","        try:\n","            midi = pretty_midi.PrettyMIDI(file)\n","            midi_data.append(midi)\n","        except Exception as e:\n","            print(f\"Skipping file {file} due to error: {e}\")\n","    return midi_data\n","\n","# Improved Data Augmentation\n","def augment_data(sequence):\n","    shift = np.random.randint(-5, 6)\n","    stretched_sequence = np.interp(np.linspace(0, len(sequence), len(sequence) * 2), np.arange(len(sequence)), sequence)\n","    return np.clip(np.array(sequence) + shift, 0, 127), np.clip(stretched_sequence, 0, 127)\n","\n","# Feature Extraction\n","def extract_features(midi_data, composer_label):\n","    features = []\n","    labels = []\n","    for midi in midi_data:\n","        if len(midi.instruments) > 0:\n","            notes = midi.instruments[0].notes\n","            pitch_sequence = [note.pitch for note in notes]\n","            features.append(pitch_sequence)\n","            labels.append(composer_label)\n","    return features, labels\n","\n","# Model evaluation function\n","def evaluate_model(model, X_test, y_test):\n","    y_pred = model.predict(X_test)\n","    y_pred_classes = np.argmax(y_pred, axis=1)\n","    y_true = np.argmax(y_test, axis=1)\n","    accuracy = accuracy_score(y_true, y_pred_classes)\n","    precision = precision_score(y_true, y_pred_classes, average='weighted', zero_division=0)\n","    recall = recall_score(y_true, y_pred_classes, average='weighted', zero_division=0)\n","    return accuracy, precision, recall\n","\n","# Main\n","if __name__ == \"__main__\":\n","    # Base directory in Google Drive\n","    base_directory = '/content/drive/My Drive/Colab Notebooks/midiclassics'\n","\n","    # Specify the subdirectories containing MIDI files\n","    composers = {\n","        'Bach': 0,\n","        'Beethoven': 1,\n","        'Chopin': 2,\n","        'Mozart': 3\n","    }\n","\n","    midi_files = []\n","    labels = []\n","\n","    # Get MIDI files from directories and assign labels\n","    for composer, label in composers.items():\n","        composer_directory = os.path.join(base_directory, composer)\n","        composer_files = get_midi_files_from_directory(composer_directory)\n","        if not composer_files:\n","            print(f\"No MIDI files found for {composer}\")\n","        composer_features, composer_labels = extract_features(preprocess_data(composer_files), label)\n","        if not composer_features:\n","            print(f\"No features extracted for {composer}\")\n","        for seq in composer_features:\n","            augmented_seq, stretched_seq = augment_data(seq)\n","            midi_files.append(seq)\n","            midi_files.append(augmented_seq)\n","            midi_files.append(stretched_seq)\n","            labels.extend([label] * 3)\n","\n","    # Pad sequences to ensure they have the same length\n","    max_sequence_length = 1000  # You can adjust this value based on your data\n","    midi_files_padded = pad_sequences(midi_files, maxlen=max_sequence_length, padding='post', truncating='post')\n","\n","    # Convert lists to numpy arrays\n","    midi_files = np.array(midi_files_padded)\n","    labels = np.array(labels)\n","\n","    # Check if dataset is empty\n","    if midi_files.shape[0] == 0:\n","        raise ValueError(\"No data available after preprocessing. Check your MIDI files and preprocessing steps.\")\n","\n","    # Reshape data to fit model input requirements\n","    X = midi_files.reshape(midi_files.shape[0], midi_files.shape[1], 1)\n","    y = to_categorical(labels, num_classes=4)\n","\n","    # Split data\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","    # Example usage with LSTM model\n","    lstm_model_custom = KerasClassifierCustom(build_fn=create_lstm_model, epochs=10, batch_size=32, verbose=0)\n","    cnn_model_custom = KerasClassifierCustom(build_fn=create_cnn_model, epochs=10, batch_size=32, verbose=0)\n","\n","    # Hyperparameter tuning for LSTM model\n","    lstm_param_grid = {\n","        'epochs': [50],\n","        'batch_size': [32],\n","        'optimizer': ['rmsprop'],\n","        'units': [64],\n","        'dropout_rate': [0.2]\n","    }\n","    lstm_grid = GridSearchCV(estimator=lstm_model_custom, param_grid=lstm_param_grid, n_jobs=-1, cv=3, error_score='raise')\n","    lstm_grid_result = lstm_grid.fit(X_train, y_train)\n","\n","    # Hyperparameter tuning for CNN model\n","    cnn_param_grid = {\n","        'epochs': [100],\n","        'batch_size': [32],\n","        'optimizer': ['adam'],\n","        'filters': [32, 64],\n","        'kernel_size': [3, 5],\n","        'dropout_rate': [0.5]\n","    }\n","    cnn_grid = GridSearchCV(estimator=cnn_model_custom, param_grid=cnn_param_grid, n_jobs=-1, cv=3, error_score='raise')\n","    cnn_grid_result = cnn_grid.fit(X_train, y_train)\n","\n","    # Print the best hyperparameters for both models\n","    print(f\"Best LSTM Model: {lstm_grid_result.best_score_} using {lstm_grid_result.best_params_}\")\n","    print(f\"Best CNN Model: {cnn_grid_result.best_score_} using {cnn_grid_result.best_params_}\")\n","\n","    # Evaluate the best LSTM model\n","    best_lstm_model = lstm_grid_result.best_estimator_.model\n","    lstm_accuracy, lstm_precision, lstm_recall = evaluate_model(best_lstm_model, X_test, y_test)\n","\n","    # Evaluate the best CNN model\n","    best_cnn_model = cnn_grid_result.best_estimator_.model\n","    cnn_accuracy, cnn_precision, cnn_recall = evaluate_model(best_cnn_model, X_test, y_test)\n","\n","    # Print evaluation results\n","    print(f\"LSTM Model - Accuracy: {lstm_accuracy}, Precision: {lstm_precision}, Recall: {lstm_recall}\")\n","    print(f\"CNN Model - Accuracy: {cnn_accuracy}, Precision: {cnn_precision}, Recall: {cnn_recall}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dakz-gvrhr_w","executionInfo":{"status":"ok","timestamp":1721620596570,"user_tz":420,"elapsed":810446,"user":{"displayName":"Aryaz Zomorodi","userId":"03185736980681493432"}},"outputId":"70ca1fa8-93b8-4908-fd42-ff94b574667d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Skipping file /content/drive/My Drive/Colab Notebooks/midiclassics/Beethoven/Anhang 14-3.mid due to error: Could not decode key with 3 flats and mode 255\n","Skipping file /content/drive/My Drive/Colab Notebooks/midiclassics/Mozart/Piano Sonatas/Nueva carpeta/K281 Piano Sonata n03 3mov.mid due to error: Could not decode key with 2 flats and mode 2\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  pid = os.fork()\n"]},{"output_type":"stream","name":"stdout","text":["115/115 [==============================] - 134s 1s/step - loss: 1.0418 - accuracy: 0.6032\n","115/115 [==============================] - 5s 37ms/step - loss: 8.9786 - accuracy: 0.5438\n","Best LSTM Model: 0.6029414847893998 using {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 50, 'optimizer': 'rmsprop', 'units': 64}\n","Best CNN Model: 0.6152119830900645 using {'batch_size': 32, 'dropout_rate': 0.5, 'epochs': 100, 'filters': 64, 'kernel_size': 5, 'optimizer': 'adam'}\n","29/29 [==============================] - 11s 363ms/step\n","29/29 [==============================] - 1s 15ms/step\n","LSTM Model - Accuracy: 0.6019629225736096, Precision: 0.5331888488829879, Recall: 0.6019629225736096\n","CNN Model - Accuracy: 0.6150490730643402, Precision: 0.5312179105085324, Recall: 0.6150490730643402\n"]}]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import pandas as pd\n","import pretty_midi\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.metrics import accuracy_score, precision_score, recall_score\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Custom wrapper\n","class KerasClassifierCustom:\n","    def __init__(self, build_fn=None, **sk_params):\n","        self.build_fn = build_fn\n","        self.sk_params = sk_params\n","        self.model = None\n","\n","    def fit(self, X, y, **fit_params):\n","        self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n","        return self.model.fit(X, y, **fit_params)\n","\n","    def predict(self, X):\n","        return self.model.predict(X)\n","\n","    def score(self, X, y):\n","        y_pred = self.predict(X)\n","        y_pred_classes = np.argmax(y_pred, axis=1)\n","        y_true = np.argmax(y, axis=1)\n","        return accuracy_score(y_true, y_pred_classes)\n","\n","    def get_params(self, deep=True):\n","        params = self.sk_params.copy()\n","        params['build_fn'] = self.build_fn\n","        return params\n","\n","    def set_params(self, **params):\n","        for key, value in params.items():\n","            if key == \"build_fn\":\n","                self.build_fn = value\n","            else:\n","                self.sk_params[key] = value\n","        return self\n","\n","    def filter_sk_params(self, fn):\n","        res = {}\n","        fn_params = fn.__code__.co_varnames[:fn.__code__.co_argcount]\n","        for name, value in self.sk_params.items():\n","            if name in fn_params:\n","                res[name] = value\n","        return res\n","\n","# Model Building\n","def create_lstm_model(optimizer='adam', units=128, dropout_rate=0.2):\n","    model = Sequential()\n","    model.add(LSTM(units, input_shape=(max_sequence_length, 1), return_sequences=True))\n","    model.add(LSTM(units))\n","    model.add(Dropout(dropout_rate))\n","    model.add(Dense(4, activation='softmax'))\n","    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n","    return model\n","\n","def create_cnn_model(optimizer='adam', filters=64, kernel_size=3, dropout_rate=0.2):\n","    model = Sequential()\n","    model.add(Conv1D(filters, kernel_size=kernel_size, activation='relu', input_shape=(max_sequence_length, 1)))\n","    model.add(MaxPooling1D(pool_size=2))\n","    model.add(Flatten())\n","    model.add(Dropout(dropout_rate))\n","    model.add(Dense(4, activation='softmax'))\n","    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n","    return model\n","\n","# Function to get MIDI file paths from a directory\n","def get_midi_files_from_directory(directory_path):\n","    midi_files = []\n","    for root, _, files in os.walk(directory_path):\n","        for file in files:\n","            if file.endswith('.mid') or file.endswith('.midi'):\n","                midi_files.append(os.path.join(root, file))\n","    return midi_files\n","\n","# Data Pre-processing\n","def preprocess_data(midi_files):\n","    midi_data = []\n","    for file in midi_files:\n","        try:\n","            midi = pretty_midi.PrettyMIDI(file)\n","            midi_data.append(midi)\n","        except Exception as e:\n","            print(f\"Skipping file {file} due to error: {e}\")\n","    return midi_data\n","\n","# Improved Data Augmentation\n","def augment_data(sequence):\n","    shift = np.random.randint(-5, 6)\n","    stretched_sequence = np.interp(np.linspace(0, len(sequence), len(sequence) * 2), np.arange(len(sequence)), sequence)\n","    return np.clip(np.array(sequence) + shift, 0, 127), np.clip(stretched_sequence, 0, 127)\n","\n","# Feature Extraction\n","def extract_features(midi_data, composer_label):\n","    features = []\n","    labels = []\n","    for midi in midi_data:\n","        if len(midi.instruments) > 0:\n","            notes = midi.instruments[0].notes\n","            pitch_sequence = [note.pitch for note in notes]\n","            features.append(pitch_sequence)\n","            labels.append(composer_label)\n","    return features, labels\n","\n","# Normalize sequences\n","def normalize_sequences(sequences):\n","    return (sequences - np.min(sequences)) / (np.max(sequences) - np.min(sequences))\n","\n","# Model evaluation function\n","def evaluate_model(model, X_test, y_test):\n","    y_pred = model.predict(X_test)\n","    y_pred_classes = np.argmax(y_pred, axis=1)\n","    y_true = np.argmax(y_test, axis=1)\n","    accuracy = accuracy_score(y_true, y_pred_classes)\n","    precision = precision_score(y_true, y_pred_classes, average='weighted', zero_division=0)\n","    recall = recall_score(y_true, y_pred_classes, average='weighted', zero_division=0)\n","    return accuracy, precision, recall\n","\n","# Main\n","if __name__ == \"__main__\":\n","    # Base directory in Google Drive\n","    base_directory = '/content/drive/My Drive/Colab Notebooks/midiclassics'\n","\n","    # Specify the subdirectories containing MIDI files\n","    composers = {\n","        'Bach': 0,\n","        'Beethoven': 1,\n","        'Chopin': 2,\n","        'Mozart': 3\n","    }\n","\n","    midi_files = []\n","    labels = []\n","\n","    # Get MIDI files from directories and assign labels\n","    for composer, label in composers.items():\n","        composer_directory = os.path.join(base_directory, composer)\n","        composer_files = get_midi_files_from_directory(composer_directory)\n","        if not composer_files:\n","            print(f\"No MIDI files found for {composer}\")\n","        composer_features, composer_labels = extract_features(preprocess_data(composer_files), label)\n","        if not composer_features:\n","            print(f\"No features extracted for {composer}\")\n","        for seq in composer_features:\n","            augmented_seq, stretched_seq = augment_data(seq)\n","            midi_files.append(seq)\n","            midi_files.append(augmented_seq)\n","            midi_files.append(stretched_seq)\n","            labels.extend([label] * 3)\n","\n","    # Pad sequences to ensure they have the same length\n","    max_sequence_length = 1000  # You can adjust this value based on your data\n","    midi_files_padded = pad_sequences(midi_files, maxlen=max_sequence_length, padding='post', truncating='post')\n","\n","    # Normalize sequences\n","    midi_files_padded = normalize_sequences(midi_files_padded)\n","\n","    # Convert lists to numpy arrays\n","    midi_files = np.array(midi_files_padded)\n","    labels = np.array(labels)\n","\n","    # Check if dataset is empty\n","    if midi_files.shape[0] == 0:\n","        raise ValueError(\"No data available after preprocessing. Check your MIDI files and preprocessing steps.\")\n","\n","    # Reshape data to fit model input requirements\n","    X = midi_files.reshape(midi_files.shape[0], midi_files.shape[1], 1)\n","    y = to_categorical(labels, num_classes=4)\n","\n","    # Split data\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","    # Example usage with LSTM model\n","    lstm_model_custom = KerasClassifierCustom(build_fn=create_lstm_model, epochs=10, batch_size=32, verbose=0)\n","    cnn_model_custom = KerasClassifierCustom(build_fn=create_cnn_model, epochs=10, batch_size=32, verbose=0)\n","\n","    # Hyperparameter tuning for LSTM model\n","    lstm_param_grid = {\n","        'epochs': [50, 100],\n","        'batch_size': [32],\n","        'optimizer': ['rmsprop', 'adam'],\n","        'units': [64, 128],\n","        'dropout_rate': [0.2, 0.5]\n","    }\n","    lstm_grid = GridSearchCV(estimator=lstm_model_custom, param_grid=lstm_param_grid, n_jobs=-1, cv=3, error_score='raise')\n","    lstm_grid_result = lstm_grid.fit(X_train, y_train)\n","\n","    # Hyperparameter tuning for CNN model\n","    cnn_param_grid = {\n","        'epochs': [50, 100],\n","        'batch_size': [32],\n","        'optimizer': ['adam'],\n","        'filters': [32, 64],\n","        'kernel_size': [3, 5],\n","        'dropout_rate': [0.5]\n","    }\n","    cnn_grid = GridSearchCV(estimator=cnn_model_custom, param_grid=cnn_param_grid, n_jobs=-1, cv=3, error_score='raise')\n","    cnn_grid_result = cnn_grid.fit(X_train, y_train)\n","\n","    # Print the best hyperparameters for both models\n","    print(f\"Best LSTM Model: {lstm_grid_result.best_score_} using {lstm_grid_result.best_params_}\")\n","    print(f\"Best CNN Model: {cnn_grid_result.best_score_} using {cnn_grid_result.best_params_}\")\n","\n","    # Evaluate the best LSTM model\n","    best_lstm_model = lstm_grid_result.best_estimator_.model\n","    lstm_accuracy, lstm_precision, lstm_recall = evaluate_model(best_lstm_model, X_test, y_test)\n","\n","    # Evaluate the best CNN model\n","    best_cnn_model = cnn_grid_result.best_estimator_.model\n","    cnn_accuracy, cnn_precision, cnn_recall = evaluate_model(best_cnn_model, X_test, y_test)\n","\n","    # Print evaluation results\n","    print(f\"LSTM Model - Accuracy: {lstm_accuracy}, Precision: {lstm_precision}, Recall: {lstm_recall}\")\n","    print(f\"CNN Model - Accuracy: {cnn_accuracy}, Precision: {cnn_precision}, Recall: {cnn_recall}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GDZIi2tsmfF2","executionInfo":{"status":"ok","timestamp":1721631572127,"user_tz":420,"elapsed":10682423,"user":{"displayName":"Aryaz Zomorodi","userId":"03185736980681493432"}},"outputId":"20dcce52-20ce-4f46-c37e-06a0e4d32ec7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Skipping file /content/drive/My Drive/Colab Notebooks/midiclassics/Beethoven/Anhang 14-3.mid due to error: Could not decode key with 3 flats and mode 255\n","Skipping file /content/drive/My Drive/Colab Notebooks/midiclassics/Mozart/Piano Sonatas/Nueva carpeta/K281 Piano Sonata n03 3mov.mid due to error: Could not decode key with 2 flats and mode 2\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  pid = os.fork()\n","/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["115/115 [==============================] - 134s 1s/step - loss: 1.0473 - accuracy: 0.6057\n","115/115 [==============================] - 5s 39ms/step - loss: 0.9750 - accuracy: 0.6024\n","Best LSTM Model: 0.6233955121848513 using {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 50, 'optimizer': 'rmsprop', 'units': 64}\n","Best CNN Model: 0.6154825295671835 using {'batch_size': 32, 'dropout_rate': 0.5, 'epochs': 100, 'filters': 64, 'kernel_size': 3, 'optimizer': 'adam'}\n","29/29 [==============================] - 10s 306ms/step\n","29/29 [==============================] - 0s 8ms/step\n","LSTM Model - Accuracy: 0.6335877862595419, Precision: 0.4620305068066262, Recall: 0.6335877862595419\n","CNN Model - Accuracy: 0.6335877862595419, Precision: 0.4718486686719356, Recall: 0.6335877862595419\n"]}]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import pandas as pd\n","import pretty_midi\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.metrics import accuracy_score, precision_score, recall_score\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.callbacks import EarlyStopping\n","from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Custom wrapper\n","class KerasClassifierCustom:\n","    def __init__(self, build_fn=None, **sk_params):\n","        self.build_fn = build_fn\n","        self.sk_params = sk_params\n","        self.model = None\n","\n","    def fit(self, X, y, **fit_params):\n","        self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n","        return self.model.fit(X, y, **fit_params)\n","\n","    def predict(self, X):\n","        return self.model.predict(X)\n","\n","    def score(self, X, y):\n","        y_pred = self.predict(X)\n","        y_pred_classes = np.argmax(y_pred, axis=1)\n","        y_true = np.argmax(y, axis=1)\n","        return accuracy_score(y_true, y_pred_classes)\n","\n","    def get_params(self, deep=True):\n","        params = self.sk_params.copy()\n","        params['build_fn'] = self.build_fn\n","        return params\n","\n","    def set_params(self, **params):\n","        for key, value in params.items():\n","            if key == \"build_fn\":\n","                self.build_fn = value\n","            else:\n","                self.sk_params[key] = value\n","        return self\n","\n","    def filter_sk_params(self, fn):\n","        res = {}\n","        fn_params = fn.__code__.co_varnames[:fn.__code__.co_argcount]\n","        for name, value in self.sk_params.items():\n","            if name in fn_params:\n","                res[name] = value\n","        return res\n","\n","# Model Building\n","def create_lstm_model(optimizer='adam', units=128, dropout_rate=0.2):\n","    model = Sequential()\n","    model.add(LSTM(units, input_shape=(max_sequence_length, 1), return_sequences=True))\n","    model.add(LSTM(units))\n","    model.add(Dropout(dropout_rate))\n","    model.add(Dense(4, activation='softmax'))\n","    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n","    return model\n","\n","def create_cnn_model(optimizer='adam', filters=64, kernel_size=3, dropout_rate=0.2):\n","    model = Sequential()\n","    model.add(Conv1D(filters, kernel_size=kernel_size, activation='relu', input_shape=(max_sequence_length, 1)))\n","    model.add(MaxPooling1D(pool_size=2))\n","    model.add(Flatten())\n","    model.add(Dropout(dropout_rate))\n","    model.add(Dense(4, activation='softmax'))\n","    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n","    return model\n","\n","# Function to get MIDI file paths from a directory\n","def get_midi_files_from_directory(directory_path):\n","    midi_files = []\n","    for root, _, files in os.walk(directory_path):\n","        for file in files:\n","            if file.endswith('.mid') or file.endswith('.midi'):\n","                midi_files.append(os.path.join(root, file))\n","    return midi_files\n","\n","# Data Pre-processing\n","def preprocess_data(midi_files):\n","    midi_data = []\n","    for file in midi_files:\n","        try:\n","            midi = pretty_midi.PrettyMIDI(file)\n","            midi_data.append(midi)\n","        except Exception as e:\n","            print(f\"Skipping file {file} due to error: {e}\")\n","    return midi_data\n","\n","# Improved Data Augmentation\n","def augment_data(sequence):\n","    shift = np.random.randint(-5, 6)\n","    stretched_sequence = np.interp(np.linspace(0, len(sequence), len(sequence) * 2), np.arange(len(sequence)), sequence)\n","    return np.clip(np.array(sequence) + shift, 0, 127), np.clip(stretched_sequence, 0, 127)\n","\n","# Feature Extraction\n","def extract_features(midi_data, composer_label):\n","    features = []\n","    labels = []\n","    for midi in midi_data:\n","        if len(midi.instruments) > 0:\n","            notes = midi.instruments[0].notes\n","            pitch_sequence = [note.pitch for note in notes]\n","            features.append(pitch_sequence)\n","            labels.append(composer_label)\n","    return features, labels\n","\n","# Normalize sequences\n","def normalize_sequences(sequences):\n","    return (sequences - np.min(sequences)) / (np.max(sequences) - np.min(sequences))\n","\n","# Model evaluation function\n","def evaluate_model(model, X_test, y_test):\n","    y_pred = model.predict(X_test)\n","    y_pred_classes = np.argmax(y_pred, axis=1)\n","    y_true = np.argmax(y_test, axis=1)\n","    accuracy = accuracy_score(y_true, y_pred_classes)\n","    precision = precision_score(y_true, y_pred_classes, average='weighted', zero_division=0)\n","    recall = recall_score(y_true, y_pred_classes, average='weighted', zero_division=0)\n","    return accuracy, precision, recall\n","\n","# Main\n","if __name__ == \"__main__\":\n","    # Base directory in Google Drive\n","    base_directory = '/content/drive/My Drive/Colab Notebooks/midiclassics'\n","\n","    # Specify the subdirectories containing MIDI files\n","    composers = {\n","        'Bach': 0,\n","        'Beethoven': 1,\n","        'Chopin': 2,\n","        'Mozart': 3\n","    }\n","\n","    midi_files = []\n","    labels = []\n","\n","    # Get MIDI files from directories and assign labels\n","    for composer, label in composers.items():\n","        composer_directory = os.path.join(base_directory, composer)\n","        composer_files = get_midi_files_from_directory(composer_directory)\n","        if not composer_files:\n","            print(f\"No MIDI files found for {composer}\")\n","        composer_features, composer_labels = extract_features(preprocess_data(composer_files), label)\n","        if not composer_features:\n","            print(f\"No features extracted for {composer}\")\n","        for seq in composer_features:\n","            augmented_seq, stretched_seq = augment_data(seq)\n","            midi_files.append(seq)\n","            midi_files.append(augmented_seq)\n","            midi_files.append(stretched_seq)\n","            labels.extend([label] * 3)\n","\n","    # Pad sequences to ensure they have the same length\n","    max_sequence_length = 1000  # You can adjust this value based on your data\n","    midi_files_padded = pad_sequences(midi_files, maxlen=max_sequence_length, padding='post', truncating='post')\n","\n","    # Normalize sequences\n","    midi_files_padded = normalize_sequences(midi_files_padded)\n","\n","    # Convert lists to numpy arrays\n","    midi_files = np.array(midi_files_padded)\n","    labels = np.array(labels)\n","\n","    # Check if dataset is empty\n","    if midi_files.shape[0] == 0:\n","        raise ValueError(\"No data available after preprocessing. Check your MIDI files and preprocessing steps.\")\n","\n","    # Reshape data to fit model input requirements\n","    X = midi_files.reshape(midi_files.shape[0], midi_files.shape[1], 1)\n","    y = to_categorical(labels, num_classes=4)\n","\n","    # Split data\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","    # Example usage with LSTM model\n","    lstm_model_custom = KerasClassifierCustom(build_fn=create_lstm_model, epochs=10, batch_size=32, verbose=0)\n","    cnn_model_custom = KerasClassifierCustom(build_fn=create_cnn_model, epochs=10, batch_size=32, verbose=0)\n","\n","    # Hyperparameter tuning for LSTM model\n","    lstm_param_grid = {\n","        'epochs': [50],\n","        'batch_size': [32],\n","        'optimizer': ['rmsprop'],\n","        'units': [64],\n","        'dropout_rate': [0.2]\n","    }\n","    lstm_grid = GridSearchCV(estimator=lstm_model_custom, param_grid=lstm_param_grid, n_jobs=-1, cv=3, error_score='raise')\n","    lstm_grid_result = lstm_grid.fit(X_train, y_train)\n","\n","    # Hyperparameter tuning for CNN model\n","    cnn_param_grid = {\n","        'epochs': [100],\n","        'batch_size': [32],\n","        'optimizer': ['adam'],\n","        'filters': [32, 64],\n","        'kernel_size': [3, 5],\n","        'dropout_rate': [0.5]\n","    }\n","    cnn_grid = GridSearchCV(estimator=cnn_model_custom, param_grid=cnn_param_grid, n_jobs=-1, cv=3, error_score='raise')\n","    cnn_grid_result = cnn_grid.fit(X_train, y_train)\n","\n","    # Print the best hyperparameters for both models\n","    print(f\"Best LSTM Model: {lstm_grid_result.best_score_} using {lstm_grid_result.best_params_}\")\n","    print(f\"Best CNN Model: {cnn_grid_result.best_score_} using {cnn_grid_result.best_params_}\")\n","\n","    # Evaluate the best LSTM model\n","    best_lstm_model = lstm_grid_result.best_estimator_.model\n","    lstm_accuracy, lstm_precision, lstm_recall = evaluate_model(best_lstm_model, X_test, y_test)\n","\n","    # Evaluate the best CNN model\n","    best_cnn_model = cnn_grid_result.best_estimator_.model\n","    cnn_accuracy, cnn_precision, cnn_recall = evaluate_model(best_cnn_model, X_test, y_test)\n","\n","    # Print evaluation results\n","    print(f\"LSTM Model - Accuracy: {lstm_accuracy}, Precision: {lstm_precision}, Recall: {lstm_recall}\")\n","    print(f\"CNN Model - Accuracy: {cnn_accuracy}, Precision: {cnn_precision}, Recall: {cnn_recall}\")\n"],"metadata":{"id":"sDq-rVqtsZrF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1721945326152,"user_tz":420,"elapsed":854363,"user":{"displayName":"Aryaz Zomorodi","userId":"04002852148298941149"}},"outputId":"a886eeba-c051-49ae-e6c8-ca9cf8fb3144"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Skipping file /content/drive/My Drive/Colab Notebooks/midiclassics/Beethoven/Anhang 14-3.mid due to error: Could not decode key with 3 flats and mode 255\n","Skipping file /content/drive/My Drive/Colab Notebooks/midiclassics/Mozart/Piano Sonatas/Nueva carpeta/K281 Piano Sonata n03 3mov.mid due to error: Could not decode key with 2 flats and mode 2\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  pid = os.fork()\n"]},{"output_type":"stream","name":"stdout","text":["115/115 [==============================] - 12s 62ms/step - loss: 1.0490 - accuracy: 0.6051\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["115/115 [==============================] - 2s 4ms/step - loss: 0.9909 - accuracy: 0.5879\n","Best LSTM Model: 0.599943838744486 using {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 50, 'optimizer': 'rmsprop', 'units': 64}\n","Best CNN Model: 0.603490830191827 using {'batch_size': 32, 'dropout_rate': 0.5, 'epochs': 100, 'filters': 32, 'kernel_size': 5, 'optimizer': 'adam'}\n","29/29 [==============================] - 1s 27ms/step\n","29/29 [==============================] - 0s 3ms/step\n","LSTM Model - Accuracy: 0.6248636859323882, Precision: 0.46579632483147193, Recall: 0.6248636859323882\n","CNN Model - Accuracy: 0.6030534351145038, Precision: 0.5011940719600039, Recall: 0.6030534351145038\n"]}]},{"cell_type":"code","source":["!pip install pretty_midi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ep_39gYx4skX","executionInfo":{"status":"ok","timestamp":1721944444411,"user_tz":420,"elapsed":5982,"user":{"displayName":"Aryaz Zomorodi","userId":"04002852148298941149"}},"outputId":"86c2fff2-1f7b-47ff-e1dd-764da71b7cb4"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pretty_midi\n","  Downloading pretty_midi-0.2.10.tar.gz (5.6 MB)\n","\u001b[?25l     \u001b[90m\u001b[0m \u001b[32m0.0/5.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m2.5/5.6 MB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m\u001b[0m\u001b[91m\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m109.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from pretty_midi) (1.25.2)\n","Collecting mido>=1.1.16 (from pretty_midi)\n","  Downloading mido-1.3.2-py3-none-any.whl.metadata (6.4 kB)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from pretty_midi) (1.16.0)\n","Collecting packaging~=23.1 (from mido>=1.1.16->pretty_midi)\n","  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n","Downloading mido-1.3.2-py3-none-any.whl (54 kB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading packaging-23.2-py3-none-any.whl (53 kB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: pretty_midi\n","  Building wheel for pretty_midi (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pretty_midi: filename=pretty_midi-0.2.10-py3-none-any.whl size=5592288 sha256=f83fe10763e8f95acccaf5895212d38b81e91e6a8330b05100bd58d4b2f0f4ba\n","  Stored in directory: /root/.cache/pip/wheels/cd/a5/30/7b8b7f58709f5150f67f98fde4b891ebf0be9ef07a8af49f25\n","Successfully built pretty_midi\n","Installing collected packages: packaging, mido, pretty_midi\n","  Attempting uninstall: packaging\n","    Found existing installation: packaging 24.1\n","    Uninstalling packaging-24.1:\n","      Successfully uninstalled packaging-24.1\n","Successfully installed mido-1.3.2 packaging-23.2 pretty_midi-0.2.10\n"]}]}]}